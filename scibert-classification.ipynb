{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:21:55.928895Z",
     "iopub.status.busy": "2025-02-23T06:21:55.928600Z",
     "iopub.status.idle": "2025-02-23T06:32:53.137574Z",
     "shell.execute_reply": "2025-02-23T06:32:53.136861Z",
     "shell.execute_reply.started": "2025-02-23T06:21:55.928867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d93251bf3a49a2bfda3e832d332a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdf0a419bc647e5b583387a446a09ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/228k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c9118c18c642eaa775438a42600d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 10:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.429700</td>\n",
       "      <td>1.316437</td>\n",
       "      <td>0.577882</td>\n",
       "      <td>0.586615</td>\n",
       "      <td>0.577882</td>\n",
       "      <td>0.572466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.623128</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.803660</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.799363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.528290</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.857257</td>\n",
       "      <td>0.839564</td>\n",
       "      <td>0.841057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.466437</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.876453</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>0.871273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.482701</td>\n",
       "      <td>0.881620</td>\n",
       "      <td>0.883025</td>\n",
       "      <td>0.881620</td>\n",
       "      <td>0.881477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[45  2  5  1  1  2  9  0]\n",
      " [ 2 32 11  0 12  3  0 14]\n",
      " [ 2  4 51  1  8 10  3 12]\n",
      " [ 0  0  2 59  0  1  1  2]\n",
      " [ 0  4 18  1 31  9  0 33]\n",
      " [ 5  0  4  1  3 39  6 13]\n",
      " [21  1  2  3  0  7 37  0]\n",
      " [ 0  0 10  0 17  2  3 77]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[45  0  7  1  1  5  6  0]\n",
      " [ 0 69  0  0  5  0  0  0]\n",
      " [ 1  5 65  0 13  2  1  4]\n",
      " [ 0  0  1 62  1  0  0  1]\n",
      " [ 0  1 12  0 66  4  1 12]\n",
      " [ 2  1  2  1  4 53  2  6]\n",
      " [ 1  0  5  0  0  2 63  0]\n",
      " [ 0  1  6  0  9  1  2 90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[52  1  4  0  1  4  2  1]\n",
      " [ 0 69  0  0  5  0  0  0]\n",
      " [ 1  5 60  0 18  3  1  3]\n",
      " [ 0  0  0 64  1  0  0  0]\n",
      " [ 0  1  3  0 88  2  0  2]\n",
      " [ 1  1  1  3  5 56  0  4]\n",
      " [ 1  0  1  2  2  1 64  0]\n",
      " [ 0  1  1  0 20  1  0 86]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[59  0  3  0  0  1  2  0]\n",
      " [ 0 69  0  0  5  0  0  0]\n",
      " [ 3  0 83  0  3  2  0  0]\n",
      " [ 0  0  0 64  1  0  0  0]\n",
      " [ 1  0 12  0 76  3  0  4]\n",
      " [ 6  1  2  1  5 52  1  3]\n",
      " [ 2  0  2  0  1  0 66  0]\n",
      " [ 0  1  6  0 10  2  0 90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[64  0  0  0  0  1  0  0]\n",
      " [ 0 69  0  0  5  0  0  0]\n",
      " [ 4  0 79  0  3  4  1  0]\n",
      " [ 0  0  1 64  0  0  0  0]\n",
      " [ 1  2  9  0 74  4  1  5]\n",
      " [ 2  1  1  1  4 58  2  2]\n",
      " [ 1  0  3  0  0  0 67  0]\n",
      " [ 0  1  5  0  9  3  0 91]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[64  0  0  0  0  1  0  0]\n",
      " [ 0 69  0  0  5  0  0  0]\n",
      " [ 4  0 79  0  3  4  1  0]\n",
      " [ 0  0  1 64  0  0  0  0]\n",
      " [ 1  2  9  0 74  4  1  5]\n",
      " [ 2  1  1  1  4 58  2  2]\n",
      " [ 1  0  3  0  0  0 67  0]\n",
      " [ 0  1  5  0  9  3  0 91]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "{'eval_loss': 0.4827011823654175, 'eval_accuracy': 0.881619937694704, 'eval_precision': 0.8830248140586462, 'eval_recall': 0.881619937694704, 'eval_f1': 0.881476510438396, 'eval_runtime': 7.6514, 'eval_samples_per_second': 83.906, 'eval_steps_per_second': 5.359, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Paths to JSON files\n",
    "train_path = \"/kaggle/input/nlp-math-question-classification-dataset/train.json\"\n",
    "test_path = \"/kaggle/input/nlp-math-question-classification-dataset/test.json\"\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"Computations with Matrices\": 0,\n",
    "    \"Determinants\": 1,\n",
    "    \"Eigenvalues and Eigenvectors\": 2,\n",
    "    \"Linear Programming and Game Theory\": 3,\n",
    "    \"Matrices and Gaussian Elimination\": 4,\n",
    "    \"Orthogonality\": 5,\n",
    "    \"Positive Definite Matrices\": 6,\n",
    "    \"Vector Spaces\": 7\n",
    "}\n",
    "\n",
    "# Load train and test JSON\n",
    "def load_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        possible_keys = [\"data\", \"questions\", \"examples\"]\n",
    "        for key in possible_keys:\n",
    "            if key in data and isinstance(data[key], list):\n",
    "                data = data[key]\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"Expected list in {json_path}, but got dictionary without a valid key.\")\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Expected a list of dictionaries in {json_path}, but got {type(data)}.\")\n",
    "\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for item in data:\n",
    "        if not isinstance(item, dict):\n",
    "            raise ValueError(f\"Invalid item in JSON: {item}. Expected a dictionary.\")\n",
    "        if \"question_latex\" not in item or \"chapter\" not in item:\n",
    "            raise KeyError(f\"Missing required keys in JSON item: {item}\")\n",
    "\n",
    "        if item[\"chapter\"] not in label_mapping:\n",
    "            raise ValueError(f\"Unknown chapter '{item['chapter']}' in JSON file.\")\n",
    "\n",
    "        texts.append(item[\"question_latex\"])\n",
    "        labels.append(label_mapping[item[\"chapter\"]])  # Map chapter to label\n",
    "        \n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = load_data(train_path)\n",
    "test_texts, test_labels = load_data(test_path)\n",
    "\n",
    "# Load SciBERT tokenizer and model\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_mapping), ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Tokenize datasets\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "test_encodings = tokenize_function(test_texts)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "    \"label\": train_labels\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": test_encodings[\"input_ids\"],\n",
    "    \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "    \"label\": test_labels\n",
    "})\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./scibert_math_classification\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",  # Disables WandB logging if not used\n",
    ")\n",
    "\n",
    "# Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"./scibert_math_model\")\n",
    "tokenizer.save_pretrained(\"./scibert_math_model\")\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6723839,
     "sourceId": 10828561,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
