{
    "questions": [
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Update\n        \\[\n        v \\leftarrow v - \\sum_{j=1}^{n} h_{j,n} q_j.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Explain the role of compressed storage formats such as Run-Length Encoding (RLE) in reducing the memory footprint of structured matrices. What are the limitations of RLE for general sparse matrices?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider the transformation matrix\n    \\[\n    S = \\begin{bmatrix} 1 & k \\\\ 0 & 1 \\end{bmatrix}.\n    \\]\n    Show that $S$ represents a shear transformation and analyze its effect on an arbitrary vector in $\\mathbb{R}^2$. Determine whether the transformation preserves angles and distances.",
            "equations": [
                "S",
                "\\mathbb{R}^2"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Discuss the parallelization of the power iteration method for computing the dominant eigenvalue of a large sparse matrix.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Explain how Graph Theory can be used to analyze sparsity patterns in matrices. Given a matrix $A$, define its adjacency graph and describe how graph partitioning techniques help in optimizing parallel sparse computations.",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a system $Ax = b$ where $A$ is nearly singular. Discuss why iterative solvers like GMRES or BiCGSTAB are preferred over direct solvers. Analyze their convergence behavior and numerical accuracy.",
            "equations": [
                "Ax = b",
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Suppose $A$ is an $n \\times n$ matrix that is nearly singular. Describe techniques for handling its inversion numerically, including regularization methods such as Tikhonov regularization.",
            "equations": [
                "A",
                "n \\times n"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "When performing high-dimensional matrix computations, distributed computing frameworks like Apache Spark and MPI-based libraries are often used. Discuss the trade-offs between accuracy and parallel efficiency in distributed matrix computations.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "The Moore-Penrose pseudoinverse $A^+$ is used for inverting singular or non-square matrices. Derive $A^+$ using Singular Value Decomposition (SVD) and explain its applications in least-squares problems.",
            "equations": [
                "A^+",
                "A^+"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a linear transformation $T: \\mathbb{R}^2 \\to \\mathbb{R}^2$ represented by a matrix $A$. Discuss how the action of $A$ on any vector $\\mathbf{v}$ can be understood geometrically in terms of basis transformations. Provide examples where $A$ represents a reflection, rotation, or shear.",
            "equations": [
                "T: \\mathbb{R}^2 \\to \\mathbb{R}^2",
                "A",
                "A",
                "\\mathbf{v}",
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "In $\\mathbb{R}^3$, the matrix\n    \\[\n    A = \\begin{bmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\n    \\]\n    represents a rotation about the $z$-axis. Compute the angle of rotation and find the eigenvectors of $A$.",
            "equations": [
                "\\mathbb{R}^3",
                "z",
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Show that for any finite-state Markov chain with transition matrix $P$, all eigenvalues satisfy $|\\lambda| \\leq 1$. Discuss the conditions under which $\\lambda = 1$ is the unique dominant eigenvalue.",
            "equations": [
                "P",
                "|\\lambda| \\leq 1",
                "\\lambda = 1"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Suppose you need to store and manipulate a sequence of time-dependent sparse matrices. What strategies would you use to minimize memory overhead while ensuring efficient access to historical data?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Homogeneous coordinates are commonly used in computer graphics to represent affine transformations. Explain why an extra dimension is introduced and derive the homogeneous transformation matrix for translation in $\\mathbb{R}^3$.",
            "equations": [
                "\\mathbb{R}^3"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Show that starting from \\( A_0 = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\), the unshifted QR algorithm produces only the modest improvement\n    \\[\n    A_1 = \\frac{1}{5} \\begin{pmatrix} 14 & -3 \\\\ -3 & 6 \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Describe an efficient method for transposing a sparse matrix stored in CSR format. How does the complexity compare to transposing a dense matrix?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "\\textbf{Arnoldi Iteration \\quad Conjugate Gradient Iteration}\n\n    \\medskip\n    \\textbf{Arnoldi Iteration:} \\\\\n    Set \n    \\[\n    q_1 = \\frac{b}{\\|b\\|}.\n    \\]\n    For \\( n = 1 \\) to \\( N-1 \\):\n    \\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "In a birth-death process represented by a tridiagonal stochastic matrix, derive the conditions under which the Markov chain is irreducible and has a unique limiting distribution.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Discuss hybrid approaches that combine direct and iterative methods for solving sparse linear systems. Provide examples where hybridization leads to significant performance gains.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Derive the necessary and sufficient conditions for the observability of a system with the state-space representation\n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t).\n    \\]\n    Define the observability matrix and show that the rank of this matrix determines the observability of the system. Use a practical example of an LTI system and compute the observability matrix to verify if the system is observable.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Many matrix computations use iterative methods (e.g., Jacobi, Gauss-Seidel) instead of direct solvers. Analyze their convergence properties and discuss the trade-offs in terms of speed, memory usage, and accuracy.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Compute the improvement factor:\n        \\[\n        \\beta_n = \\frac{r_n^T r_n}{r_{n-1}^T r_{n-1}}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Prove that if $A$ is an orthogonal matrix, then $A^{-1} = A^T$. Discuss the implications of this property for numerical computation and stability in solving linear systems.",
            "equations": [
                "A",
                "A^{-1} = A^T"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Apply to the following matrix \\( A \\) a single QR step with the shift \\( \\alpha = a_{22} \\)\u2014which in this case means without shift, since \\( a_{22} = 0 \\). Show that the off-diagonal entries go from \\( \\sin \\theta \\) to \\( -\\sin 3\\theta \\), which is cubic convergence.\n    \\[\n    A = \\begin{pmatrix} \\cos \\theta & \\sin \\theta \\\\ \\sin \\theta & 0 \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a block matrix $A$ that is partitioned into submatrices for parallel processing. Explain how an optimal block size can be chosen to balance computation and communication overhead in a distributed memory system.",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Given a symmetric sparse matrix with bandwidth $b$, analyze the computational complexity of performing Cholesky factorization. Compare the complexity with that of a full dense matrix.",
            "equations": [
                "b"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Discuss why a matrix with linearly dependent columns collapses the dimensionality of the space. Provide examples where a $3 \\times 3$ matrix maps $\\mathbb{R}^3$ onto a plane.",
            "equations": [
                "3 \\times 3",
                "\\mathbb{R}^3"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "When \\(A = A^T\\), the Arnoldi-Lanczos method finds orthonormal vectors \\(q_j\\) such that\n    \\[\n    Aq_j = b_{j-1}q_{j-1} + a_jq_j + b_jq_{j+1} \\quad (q_0 = 0).\n    \\]\n    Multiply by \\(q_j^T\\) to derive a formula for \\(a_j\\). This equation indicates that \\(AQ = Q^T T\\), where \\(T\\) is a tridiagonal matrix.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Describe the role of Householder reflections in QR decomposition. Compare them to the Gram-Schmidt process in terms of numerical stability and computational efficiency.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a high-performance computing system executing parallel matrix computations. Discuss strategies for optimizing energy efficiency while maintaining computational throughput.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Write a computer code (MATLAB or other) for Gauss-Seidel. You can define \\(S\\) and \\(T\\) from \\(A\\), or set up the iteration loop directly from the entries \\(a_{ij}\\). Test it on the \\(-1,\\,2,\\,-1\\) matrices \\(A\\) of order 10, 20, and 50, with \\(b = (1,0,\\dots,0)\\).",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "If \\(A\\) is singular, then all splittings \\(A = S - T\\) must fail. From \\(Ax = 0\\), show that\n    \\[\n    S^{-1}T x = x.\n    \\]\n    Thus, the matrix \\(B = S^{-1}T\\) has an eigenvalue \\(\\lambda = 1\\) and fails.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Update the approximate solution:\n        \\[\n        x_n = x_{n-1} + \\alpha_n\\, p_{n-1}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "The composition of two linear transformations $T_1$ and $T_2$ corresponds to matrix multiplication. Show how the order of multiplication affects the geometric interpretation of transformations.",
            "equations": [
                "T_1",
                "T_2"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "How does the sparsity pattern of a matrix affect the numerical stability of sparse direct solvers? Provide examples where poor conditioning arises due to sparsity structure.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a system of linear equations $Ax = b$ where $A$ is a large distributed matrix. Discuss iterative methods such as Jacobi and Gauss-Seidel that can be parallelized. Compare their convergence properties.",
            "equations": [
                "Ax = b",
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "In conjugate gradients, show that the residual \\( r_1 \\) is orthogonal to \\( r_0 \\) (i.e. the residuals are orthogonal), and that the search directions satisfy\n    \\[\n    p_0^T A p_0 = 0.\n    \\]\n    Explain why the iteration solves \\( Ax = b \\) by minimizing the error \\( e^T A e \\) in the Krylov subspace. (This is one of the remarkable properties of the conjugate gradient method.)",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Prove that \\( \\|x\\|_\\infty \\leq \\|x\\|_2 \\leq \\|x\\|_1 \\). Show from the Cauchy-Schwarz inequality that the ratios \\( \\|x\\|_2 / \\|x\\|_\\infty \\) and \\( \\|x\\|_1 / \\|x\\|_2 \\) are never larger than \\( \\sqrt{n} \\). Which vector \\( (x_1, \\dots, x_n) \\) gives ratios equal to \\( \\sqrt{n} \\)?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a matrix $A$ with condition number $\\kappa(A)$. Explain how $\\kappa(A)$ influences numerical errors in computed solutions when using floating-point arithmetic. Provide examples illustrating how small perturbations in input data affect the solution.",
            "equations": [
                "A",
                "\\kappa(A)",
                "\\kappa(A)"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a state-space model of a system where the system matrix $A$ is diagonalizable. Show that the solution to the differential equation $\\dot{x}(t) = Ax(t) + Bu(t)$ can be expressed as a matrix exponential. Provide the explicit form of the solution, including the influence of the control input $u(t)$ on the state evolution. Illustrate this with an example involving specific values for $A$ and $B$.",
            "equations": [
                "A",
                "\\dot{x}(t) = Ax(t) + Bu(t)",
                "u(t)",
                "A",
                "B"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Discuss the trade-offs between explicit and implicit storage of large permutation matrices in numerical linear algebra applications.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a sparse matrix $A$ distributed across multiple GPUs. How can the sparse matrix-vector product (SpMV) be optimized to achieve high performance? Discuss trade-offs between memory access patterns and computational throughput.",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Compute the new residual:\n        \\[\n        r_n = r_{n-1} - \\alpha_n\\, A p_{n-1}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "In large-scale simulations involving finite element methods (FEM), how can sparsity patterns be exploited to optimize memory usage?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Define the concept of isotropic scaling, anisotropic scaling, and shear transformations in $\\mathbb{R}^3$. Discuss the geometric interpretation of each using suitable transformation matrices.",
            "equations": [
                "\\mathbb{R}^3"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "(a) Do \\( A \\) and \\( A^{-1} \\) have the same condition number \\( c \\)? \\\\\n    (b) In parallel with the upper bound (8) on the error, prove a lower bound: \\( \\frac{\\|\\delta x\\|}{\\|x\\|} \\geq \\frac{1}{c} \\frac{\\|\\delta b\\|}{\\|b\\|} \\). (Consider \\( A^{-1} b = x \\) instead of \\( Ax = b \\).)",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Choose \\( \\sin \\theta \\) and \\( \\cos \\theta \\) in the rotation \\( P_{21} \\) to triangularize \\( A \\), and find \\( R \\):\n    \\[\n    P_{21} A = \\begin{pmatrix} \\cos \\theta & -\\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix} \\begin{pmatrix} 1 & -1 \\\\ 3 & 5 \\end{pmatrix} = \\begin{pmatrix} * & * \\\\ 0 & * \\end{pmatrix} = R.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Investigate the use of the Laplacian matrix in network flow analysis. Derive the conditions under which the flow in a network can be modeled by the eigenvectors of the Laplacian matrix. Discuss the applications of this result in optimizing network flows and computing minimum cuts. Provide an example of a flow network and demonstrate the use of the Laplacian eigenvectors.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Given a transformation matrix $A$ with eigenvalues $\\lambda_1, \\lambda_2, \\lambda_3$, explain how the determinant and trace of $A$ relate to its geometric properties.",
            "equations": [
                "A",
                "\\lambda_1, \\lambda_2, \\lambda_3",
                "A"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Explain how a non-diagonalizable matrix corresponds to a transformation that does not have a complete set of linearly independent eigenvectors. Provide a geometric interpretation.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Define the concept of a stable algorithm in matrix decomposition. Provide examples of numerically stable and unstable algorithms for computing matrix inverses.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Given a linear time-invariant (LTI) system with the state-space representation \n    \\[\n    \\dot{x}(t) = Ax(t) + Bu(t), \\quad y(t) = Cx(t) + Du(t),\n    \\]\n    where $A$, $B$, $C$, and $D$ are matrices of appropriate dimensions, discuss the conditions under which this system is controllable. Provide a detailed derivation of the controllability matrix and explain how to use the matrix rank condition to determine whether the system is controllable. Include an example of an LTI system and perform a controllability analysis using the controllability matrix.",
            "equations": [
                "A",
                "B",
                "C",
                "D"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Describe the impact of matrix compression techniques such as Hierarchical Matrices (H-Matrices) and Tensor Train decomposition on optimizing sparse computations.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Compute the step length\n        \\[\n        \\alpha_n = \\frac{r_{n-1}^T r_{n-1}}{p_{n-1}^T A p_{n-1}}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Suppose a machine learning model requires storing an extremely large covariance matrix. How can low-rank approximations (e.g., Singular Value Decomposition, CUR decomposition) help in reducing memory consumption?",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Given a reducible Markov chain with a block diagonal transition matrix, explain how the system decomposes into smaller independent Markov chains. Discuss implications for long-term behavior.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Define the concept of the graph\u2019s spectral radius in terms of the adjacency matrix. Discuss its implications for the network's stability, and prove a relationship between the spectral radius and the largest eigenvalue of the graph\u2019s Laplacian matrix. Use an example to illustrate the concept of the spectral radius in the context of a strongly connected graph.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Explain the trade-offs between dense and sparse matrix storage formats in terms of memory efficiency, computational complexity, and ease of implementation. Provide examples where one format significantly outperforms the other.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Consider a Markov chain with transition matrix $P$. Prove that if $P$ is symmetric, then all its eigenvalues are real. Discuss the implications of this property in terms of convergence to equilibrium.",
            "equations": [
                "P",
                "P"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "In deep learning, sparse weight matrices are often used to reduce computational cost. Describe how pruning techniques affect sparse matrix computations and propose an efficient algorithm for performing sparse-dense matrix multiplications in neural network training.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "The trade-off between storage and accuracy is particularly important for large matrices. Compare dense matrix representations with compressed sparse formats in terms of numerical stability and memory efficiency.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Given a linear transformation $T$ that scales all vectors by a factor $\\lambda$, show that $T$ has $\\lambda$ as its only eigenvalue. Provide examples where this occurs.",
            "equations": [
                "T",
                "\\lambda",
                "T",
                "\\lambda"
            ]
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Many real-world problems involve computing the inverse of a nearly singular matrix. Compare Tikhonov regularization and truncated SVD as methods to handle this situation, discussing accuracy versus efficiency.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Describe how matrix inversion can be efficiently implemented using parallel computing techniques. Compare the performance of LU decomposition, Gauss-Jordan elimination, and block matrix inversion in a multi-core system.",
            "equations": []
        },
        {
            "chapter": "Computations with Matrices",
            "question_latex": "Define the concept of detailed balance in a reversible Markov chain. Prove that if a stationary distribution $\\pi$ satisfies the detailed balance equation $\\pi_i P_{ij} = \\pi_j P_{ji}$, then the chain is time-reversible.",
            "equations": [
                "\\pi",
                "\\pi_i P_{ij} = \\pi_j P_{ji}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the following matrix:\n    \\[\n    A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 2 & 2 & 2 \\\\ 3 & 3 & 3 \\end{pmatrix}\n    \\]\n    Compute its determinant and inverse, and discuss the implications of the determinant being zero. What does this imply about the rank and the invertibility of \\( A \\)?",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Using MATLAB, find the largest determinant of a 4 by 4 matrix of 0s and 1s.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given the matrix \n    \\[\n    A = \\begin{pmatrix} \n    1 & 3 & 2 \\\\ \n    4 & 2 & 1 \\\\ \n    5 & 6 & 3\n    \\end{pmatrix},\n    \\]\n    compute the determinant of \\( A \\) using cofactor expansion. Next, use the LU decomposition method to compute the determinant of the same matrix and compare the results. Discuss the efficiency of each method in solving real-world problems such as numerical optimization.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let the points \\( A = (1, 1), B = (4, 2), C = (3, 5) \\) define a triangle in the plane. Use the determinant method to find the area of the triangle. Also, show how this formula generalizes to triangles in higher dimensions.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Problems 24\u201333 use cofactors $C_{ij} = (-1)^{i+j} \\det M_{ij}$. Delete row $i$, column $j$.\n    \\begin{enumerate}",
            "equations": [
                "C_{ij} = (-1)^{i+j} \\det M_{ij}",
                "i",
                "j"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "L is lower triangular and S is symmetric. Assume they are invertible:\n    \\[\n    L = \\begin{bmatrix} \n    a & 0 & 0 \\\\\n    b & c & 0 \\\\\n    d & e & f\n    \\end{bmatrix}, \\quad S = \\begin{bmatrix} \n    a & b & d \\\\\n    b & c & e \\\\\n    d & e & f\n    \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} \n    1 & 2 & 3 \\\\ \n    0 & 1 & 4 \\\\ \n    5 & 6 & 0\n    \\end{pmatrix} \\). Compute the determinant of \\( A \\) using cofactor expansion along the first row. Subsequently, use the formula for minors and cofactors to compute the determinant and verify the result through row reduction. Explain how these methods relate to the underlying properties of matrix determinants.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "How many $5 \\times 5$ permutation matrices have $\\det P = +1$? Those are even permutations. Find one that needs four exchanges to reach the identity matrix.",
            "equations": [
                "5 \\times 5",
                "\\det P = +1"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "$2x_1 + x_2 = 1$ \\quad and \\quad $x_1 + 2x_2 + x_3 = 70$ \\quad and \\quad $x_2 + 2x_3 = 0$.",
            "equations": [
                "2x_1 + x_2 = 1",
                "x_1 + 2x_2 + x_3 = 70",
                "x_2 + 2x_3 = 0"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the matrix \\( A = \\begin{pmatrix} 0 & 1 & 2 \\\\ 3 & 1 & 0 \\\\ 1 & 4 & 5 \\end{pmatrix} \\). Calculate the volume of the parallelepiped formed by the columns of \\( A \\) using the determinant. Explain how the determinant behaves as a measure of volume in three-dimensional space and the relationship between the rows and columns in the matrix.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find the area of the triangle formed by the points \\( A = (0, 0), B = (1, 2), C = (3, 3) \\) in \\( \\mathbb{R}^2 \\) using determinants. Discuss the conditions under which the determinant-based formula for the area may yield zero and its interpretation in terms of the geometry of the triangle.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Using the formula for minors and cofactors, compute the determinant of the following matrix:\n    \\[\n    A = \\begin{pmatrix} \n    7 & 4 & 2 \\\\ \n    5 & 3 & 1 \\\\ \n    9 & 6 & 3\n    \\end{pmatrix}.\n    \\]\n    Additionally, show how the determinant can be used to verify the linear independence of the rows or columns of a matrix. Discuss how this property can be useful in applications such as determining the rank of a matrix and solving systems of linear equations.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If $\\det A > 0$, show that $A$ can be connected to $I$ by a continuous chain of matrices $A(t)$ all with positive determinants. (The straight path $A(t) = A + t(I - A)$ does go from $A(0) = A$ to $A(1) = I$, but in between $A(t)$ might be singular. The problem is not so easy, and solutions are welcomed by the author.)",
            "equations": [
                "\\det A > 0",
                "A",
                "I",
                "A(t)",
                "A(t) = A + t(I - A)",
                "A(0) = A",
                "A(1) = I",
                "A(t)"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Suppose $(x,y,z)$, $(1,1,0)$, and $(1,2,1)$ lie on a plane through the origin. What determinant is zero? What equation does this give for the plane?",
            "equations": [
                "(x,y,z)",
                "(1,1,0)",
                "(1,2,1)"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Expand those determinants in cofactors of the first row. Find the cofactors (they include the signs \\( (-1)^{i+j} \\)) and the determinants of \\( A \\) and \\( B \\).",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If the points $(x,y,z)$, $(2,1,0)$, and $(1,1,1)$ lie on a plane through the origin, what determinant is zero? Are the vectors $(1,0,-1)$, $(2,1,0)$, $(1,1,1)$ independent?",
            "equations": [
                "(x,y,z)",
                "(2,1,0)",
                "(1,1,1)",
                "(1,0,-1)",
                "(2,1,0)",
                "(1,1,1)"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the system of equations\n    \\[\n    \\begin{aligned}\n    5x + 2y + 3z &= 12, \\\\\n    x + 4y - z &= 2, \\\\\n    3x - y + 2z &= 5.\n    \\end{aligned}\n    \\]\n    Solve this system using Cramer's Rule. Calculate each determinant step-by-step, and determine if the system has a unique solution, infinitely many solutions, or no solution.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Using the cofactor matrix, find the inverse of the matrix\n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 1 \\\\ 2 & 3 & 3 \\\\ 1 & 1 & 2 \\end{pmatrix}.\n    \\]\n    Verify the result by checking if the product of \\( A \\) and its inverse equals the identity matrix.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given the matrix \\( D = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\), calculate the determinant and determine whether the permutation of rows in \\( D \\) is even or odd. How does the parity of the permutation affect the value of the determinant, and what conclusions can be drawn from this observation?",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find all the odd permutations of the numbers $\\{1,2,3,4\\}$. They come from an odd number of exchanges and lead to $\\det(P) = -1$.",
            "equations": [
                "\\{1,2,3,4\\}",
                "\\det(P) = -1"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} 2 & 1 & 3 & 4 \\\\ 5 & 2 & 1 & 3 \\\\ 7 & 3 & 2 & 4 \\\\ 1 & 5 & 6 & 7 \\end{pmatrix}.\n    \\]\n    Use Gaussian elimination to reduce this matrix to row echelon form, and then compute its determinant. Afterward, investigate the effect of performing Gaussian elimination with partial pivoting on the accuracy and stability of the determinant computation.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If $a_{11} = a_{22} = a_{33} = a_{44} = 0$, how many of the 24 products $a_{1j}a_{2k}a_{3\\ell}a_{4m}$ are sure to be zero?",
            "equations": [
                "a_{11} = a_{22} = a_{33} = a_{44} = 0",
                "a_{1j}a_{2k}a_{3\\ell}a_{4m}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Which three cofactors of $L$ are zero? Then $L^{-1}$ is lower triangular.",
            "equations": [
                "L",
                "L^{-1}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "The corners of a triangle are $(2,1)$, $(3,4)$, and $(0,5)$. What is the area?",
            "equations": [
                "(2,1)",
                "(3,4)",
                "(0,5)"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Which three pairs of cofactors of $S$ are equal? Then $S^{-1}$ is symmetric.",
            "equations": [
                "S",
                "S^{-1}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "What formula for $x_1$ comes from left side = right side?",
            "equations": [
                "x_1"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 3 \\\\ 2 & 3 & 4 \\end{pmatrix} \\) be the matrix representing the vectors forming a parallelepiped. Compute the volume of the parallelepiped formed by the column vectors of \\( A \\) using the determinant. Discuss the effects of scaling and rotations on the volume as represented by the determinant.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the block matrix\n    \\[\n    A = \\begin{pmatrix} \n    1 & 0 & 0 \\\\ \n    0 & A_{22} & A_{23} \\\\ \n    0 & A_{32} & A_{33} \n    \\end{pmatrix},\n    \\]\n    where \\( A_{22} \\), \\( A_{23} \\), \\( A_{32} \\), and \\( A_{33} \\) are square matrices of size \\( n \\times n \\). Show that the determinant of \\( A \\) can be computed as the product\n    \\[\n    \\det(A) = \\det(A_{22}) \\det(A_{33} - A_{32} A_{22}^{-1} A_{23}).\n    \\]\n    Apply this result to compute the determinant of the block matrix\n    \\[\n    A = \\begin{pmatrix}\n    1 & 0 & 0 \\\\\n    0 & 2 & 1 \\\\\n    0 & 1 & 3\n    \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A \\) be an orthogonal matrix, i.e., \\( A^T A = I \\). Prove that the determinant of an orthogonal matrix is either \\( 1 \\) or \\( -1 \\), and provide a detailed explanation of why this property holds. As an example, compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    0 & 1 \\\\ \n    -1 & 0\n    \\end{pmatrix}.\n    \\]\n    Discuss the significance of this result in the context of rotations in Euclidean space and the preservation of volume by orthogonal transformations.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Explain in terms of volumes why $\\det(3A) = 3^n \\det(A)$ for an $n \\times n$ matrix $A$.",
            "equations": [
                "\\det(3A) = 3^n \\det(A)",
                "n \\times n",
                "A"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Prove that for any square matrix \\( A \\), the determinant satisfies the multilinearity property, i.e., for vectors \\( \\mathbf{v}_1, \\dots, \\mathbf{v}_n \\in \\mathbb{R}^n \\), the determinant is linear in each row of the matrix. Specifically, show that if one row of a matrix is a linear combination of two other rows, then the determinant of the matrix is zero. Discuss the implications of this property for solving systems of linear equations.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given a matrix \\( A \\in \\mathbb{R}^{n \\times n} \\), define the matrix \\( A + \\delta A \\) as a perturbation of \\( A \\), where \\( \\delta A \\) represents a small change. Using perturbation theory, derive a bound for the relative error in \\( \\det(A + \\delta A) \\) in terms of the norm of \\( \\delta A \\) and the condition number of \\( A \\). Discuss the computational techniques to mitigate the effects of large errors when calculating determinants in practical scenarios.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find the determinant and all nine cofactors $C_{ij}$ of this triangular matrix:\n    \\[\n    A = \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    0 & 4 & 0 \\\\\n    0 & 0 & 5\n    \\end{bmatrix}\n    \\]\n    Form $C^T$ and verify that $A C^T = (\\det A) I$. What is $A^{-1}$?",
            "equations": [
                "C_{ij}",
                "C^T",
                "A C^T = (\\det A) I",
                "A^{-1}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Use the method of LU decomposition to compute the determinant of the matrix \n    \\[\n    A = \\begin{pmatrix} \n    4 & 3 & 2 \\\\ \n    2 & 1 & 3 \\\\ \n    3 & 2 & 1\n    \\end{pmatrix}.\n    \\]\n    Compute the LU factorization and use the property \\( \\det(A) = \\det(L) \\det(U) \\) to find the determinant. Compare the result with the cofactor expansion method and discuss the computational efficiency of LU decomposition for larger matrices.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider a square matrix \\( A \\in \\mathbb{C}^{n \\times n} \\) and its Singular Value Decomposition \\( A = U \\Sigma V^H \\), where \\( U \\) and \\( V \\) are unitary matrices and \\( \\Sigma \\) is a diagonal matrix of singular values. Derive the relationship between the determinant of \\( A \\) and the singular values in \\( \\Sigma \\). Specifically, express \\( \\det(A) \\) as the product of the singular values and discuss how this provides insight into the geometric properties of the matrix.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given the matrix \\( A = \\begin{pmatrix} 4 & 1 & 3 \\\\ 2 & 2 & 1 \\\\ 1 & 3 & 2 \\end{pmatrix} \\), compute the volume of the parallelepiped formed by the columns of \\( A \\). Discuss how the determinant relates to the geometric volume and how row/column exchanges affect the determinant value.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Show that for a block matrix \\( A = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\), if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Use this formula to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    5 & 3 & 1 & 0 \\\\\n    3 & 5 & 0 & 1 \\\\\n    1 & 0 & 6 & 2 \\\\\n    0 & 1 & 2 & 6\n    \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Solve the system of equations\n    \\[\n    \\begin{aligned}\n    4x + 3y - 2z &= 5, \\\\\n    2x + y + z &= 3, \\\\\n    x - y + 2z &= 1,\n    \\end{aligned}\n    \\]\n    using Cramer's Rule. Explicitly compute the determinants of the coefficient matrix and the matrices obtained by replacing columns with the constant vector.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "This problem shows in two ways that $\\det A = 0$ (the $x$'s are any numbers):\n    \\[\n    A =\n    \\begin{bmatrix}\n    x & x & x & x & x \\\\\n    x & x & x & x & x \\\\\n    0 & 0 & 0 & x & x \\\\\n    0 & 0 & 0 & x & x \\\\\n    0 & 0 & 0 & x & x\n    \\end{bmatrix}.\n    \\]\n    \\begin{enumerate}",
            "equations": [
                "\\det A = 0",
                "x"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Count row exchanges to find these determinants:\n    \\[\n    \\det \\begin{bmatrix}\n    0 & 0 & 0 & 1 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1 & 0 & 0 & 0\n    \\end{bmatrix} = \\pm 1\n    \\]\n    and\n    \\[\n    \\det \\begin{bmatrix}\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 0 \\\\\n    0 & 0 & 0 & 1 \\\\\n    1 & 0 & 0 & 0\n    \\end{bmatrix} = -1.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "(MATLAB) What is a typical determinant (experimentally) of \\texttt{rand(n)} and \\texttt{randn(n)} for \\( n = 50, 100, 200, 400 \\)? (And what does \"Inf\" mean in MATLAB?)\n    \\setcounter{enumi}{32} % Start enumeration at 33",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Suppose the $4 \\times 4$ matrix $M$ has four equal rows all containing $a, b, c, d$. We know that $\\det(M) = 0$. The problem is to find $\\det(I + M)$ by any method:\n    \\[\n    I + M =\n    \\begin{vmatrix}\n    1 + a & b & c & d \\\\\n    a & 1 + b & c & d \\\\\n    a & b & 1 + c & d \\\\\n    a & b & c & 1 + d \\\\\n    \\end{vmatrix}\n    \\]\n    Partial credit if you find this determinant when $a = b = c = d = 1$. Sudden death if you say that $\\det(I + M) = \\det I + \\det M$.",
            "equations": [
                "4 \\times 4",
                "M",
                "a, b, c, d",
                "\\det(M) = 0",
                "\\det(I + M)",
                "a = b = c = d = 1",
                "\\det(I + M) = \\det I + \\det M"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "How many multiplications are required to find an \\( n \\times n \\) determinant from:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\) be a block matrix where \\( A_{11} \\) and \\( A_{22} \\) are square matrices. Prove that if \\( A_{11} \\) is invertible, then the determinant of \\( A \\) is\n    \\[\n    \\det(A) = \\det(A_{11}) \\det(A_{22} - A_{21} A_{11}^{-1} A_{12}).\n    \\]\n    Apply this formula to compute the determinant of the matrix\n    \\[\n    A = \\begin{pmatrix}\n    8 & 2 & 1 & 0 \\\\\n    2 & 8 & 0 & 1 \\\\\n    1 & 0 & 9 & 4 \\\\\n    0 & 1 & 4 & 9\n    \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider a parallelepiped in 3D space defined by the vectors \\( \\mathbf{v}_1 = (2, 0, 1), \\mathbf{v}_2 = (1, 3, 0), \\mathbf{v}_3 = (0, 1, 2) \\). Find the volume of this parallelepiped using the determinant of the matrix formed by these vectors. Discuss how the determinant calculation captures the 3D nature of the volume.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Expand in cofactors along the first row to show that \\( D_n = D_{n-1} - D_{n-2} \\).",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Discuss the perturbation theory for the eigenvalues of symmetric matrices. Derive a first-order approximation for the change in the determinant of a symmetric matrix \\( A \\) when it is perturbed by a small symmetric matrix \\( E \\). How does the spectral theorem help in analyzing the effects of such perturbations, and what insights can be gained about the stability of determinants in this specific case?",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given the matrix\n    \\[\n    A = \\begin{pmatrix} 2 & 4 \\\\ 1 & 2 \\end{pmatrix},\n    \\]\n    compute its determinant using cofactor expansion and explain how the determinant relates to the area of a rectangle in the plane.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "The matrix that connects $r$, $\\theta$ to $x$, $y$ is in Problem 37. Invert that matrix:\n        \\[\n        J^{-1} = \\left| \\begin{matrix}\n        \\frac{\\partial r}{\\partial x} & \\frac{\\partial r}{\\partial y} \\\\\n        \\frac{\\partial \\theta}{\\partial x} & \\frac{\\partial \\theta}{\\partial y}\n        \\end{matrix} \\right| = \\left| \\begin{matrix}\n        \\cos \\theta & ? \\\\\n        ? & ?\n        \\end{matrix} \\right| = ?\n        \\]\n        It is surprising that $\\frac{\\partial r}{\\partial x} = \\frac{\\partial x}{\\partial r}$. The product $JJ^{-1} = I$ gives the chain rule:\n        \\[\n        \\frac{\\partial x}{\\partial x} = \\frac{\\partial x}{\\partial r} \\frac{\\partial r}{\\partial x} + \\frac{\\partial x}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial x} = 1.\n        \\]",
            "equations": [
                "r",
                "\\theta",
                "x",
                "y",
                "\\frac{\\partial r}{\\partial x} = \\frac{\\partial x}{\\partial r}",
                "JJ^{-1} = I"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "If every row of \\( A \\) adds to zero, prove that \\( \\det A = 0 \\). If every row adds to 1, prove that \\( \\det(A - I) = 0 \\). Show by example that this does not imply \\( \\det A = 1 \\).",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If the right side $b$ is the last column of $A$, solve the $3 \\times 3$ system $A x = b$. Explain how each determinant in Cramer's Rule leads to your solution $x$.",
            "equations": [
                "b",
                "A",
                "3 \\times 3",
                "A x = b",
                "x"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "This problem shows in two ways that $\\det A = 0$ (the $x$'s are any numbers):\n\\[\nA =\n\\begin{bmatrix}\nx & x & x & x & x \\\\\nx & x & x & x & x \\\\\n0 & 0 & 0 & x & x \\\\\n0 & 0 & 0 & x & x \\\\\n0 & 0 & 0 & x & x\n\\end{bmatrix}\n\\]\n\\begin{itemize}",
            "equations": [
                "\\det A = 0",
                "x"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "the upper triangular matrix\n        \\[\n        U = \\begin{bmatrix}\n        4 & 4 & 8 & 8 \\\\\n        0 & 1 & 2 & 2 \\\\\n        0 & 0 & 2 & 6 \\\\\n        0 & 0 & 0 & 2\n        \\end{bmatrix};\n        \\]",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A \\) be a matrix of the form \n    \\[\n    A = \\begin{pmatrix} \n    2 & 4 & 1 \\\\ \n    0 & 3 & 5 \\\\ \n    6 & 7 & 8\n    \\end{pmatrix}.\n    \\]\n    Using the cofactor expansion method, compute the determinant of \\( A \\). Then, use row operations to simplify \\( A \\) and verify your result. Discuss how row operations simplify the calculation and the role of the determinant in understanding the invertibility of the matrix.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Given the matrix \\( A = \\begin{pmatrix} \n    4 & 2 & 1 \\\\ \n    3 & 1 & 2 \\\\ \n    1 & 3 & 4\n    \\end{pmatrix} \\), compute the determinant of \\( A \\) by applying the cofactor expansion method along the second row. Then, using this result, compute the minor and cofactor for the entry in the second row, first column. Discuss the geometric interpretation of the determinant in terms of the volume of a parallelepiped.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If $Ax = (1, 0, \\dots, 0)$, show how Cramer's Rule gives $x = \\text{first column of } A^{-1}$.",
            "equations": [
                "Ax = (1, 0, \\dots, 0)",
                "x = \\text{first column of } A^{-1}"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find the determinant when a vector $x$ replaces column $j$ of the identity (consider $x_j = 0$ as a separate case):\n        \\[\n        M = \\begin{bmatrix}\n        1 & x_1 \\\\\n        1 & \\cdot \\\\\n        x_j & \\cdot \\\\\n        1 & x_n \\\\\n        1\n        \\end{bmatrix}\n        \\]\n        then $\\det M = \\ldots$.",
            "equations": [
                "x",
                "j",
                "x_j = 0",
                "\\det M = \\ldots"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find two ways to choose nonzeros from four different rows and columns:\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 1 \\\\\n    0 & 1 & 1 & 1 \\\\\n    1 & 1 & 0 & 1 \\\\\n    1 & 0 & 0 & 1\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 2 \\\\\n    0 & 3 & 4 & 5 \\\\\n    5 & 4 & 0 & 3 \\\\\n    2 & 0 & 0 & 1\n    \\end{bmatrix}.\n    \\]\n    (B has the same zeros as A.) Is $\\det A$ equal to $1+1$, $1-1$, or $-1-1$? What is $\\det B$?",
            "equations": [
                "\\det A",
                "1+1",
                "1-1",
                "-1-1",
                "\\det B"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\). Compute the inverse of \\( A \\) using its cofactor matrix. What does the result suggest about the identity matrix and its properties?",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If every row of $A$ has either a single $+1$, or a single $-1$, or one of each (and is otherwise zero), show that $\\det A = 1$ or $-1$ or $0$.",
            "equations": [
                "A",
                "+1",
                "-1",
                "\\det A = 1",
                "-1",
                "0"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} \\) be a matrix. Compute the determinant of \\( A \\) and determine whether the permutation represented by the matrix is even or odd. Discuss the relationship between the determinant and the parity of permutations.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Find the LU factorization, the pivots, and the determinant of the 4 by 4 matrix whose entries are \\( a_{ij} = \\min(i, j) \\). (Write out the matrix.)",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "The Hadamard matrix $H$ has orthogonal rows. The box is a hypercube! What is\n    \\[\n    \\det(H) = \\left| \\begin{array}{cccc} \n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & -1 & -1 \\\\\n    1 & -1 & -1 & 1 \\\\\n    1 & -1 & 1 & -1\n    \\end{array} \\right|\n    \\]\n    (volume of a hypercube in $\\mathbb{R}^4$)?",
            "equations": [
                "H",
                "\\mathbb{R}^4"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Show that $\\det A = 0$ if $ad = bc$ (so $C$ is singular).",
            "equations": [
                "\\det A = 0",
                "ad = bc",
                "C"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "If \\( A \\) and \\( B \\) are identical except that \\( b_{11} = 2a_{11} \\), then \\( \\det B = 2 \\det A \\).",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "If a 3 by 3 matrix has $\\det(A) = -1$, find $\\det\\left(\\frac{1}{2}A\\right)$, $\\det(-A)$, $\\det(A^2)$, and $\\det(A^{-1})$.",
            "equations": [
                "\\det(A) = -1",
                "\\det\\left(\\frac{1}{2}A\\right)",
                "\\det(-A)",
                "\\det(A^2)",
                "\\det(A^{-1})"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Starting with $A$, multiply its first row by 3 to produce $B$, and subtract the first row of $B$ from the second to produce $C$. How is $\\det C$ related to $\\det A$?",
            "equations": [
                "A",
                "B",
                "B",
                "C",
                "\\det C",
                "\\det A"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the matrix \n    \\[\n    A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 4 \\\\ 0 & 0 & 1 \\end{pmatrix}.\n    \\]\n    Perform Gaussian elimination on \\( A \\) and find its determinant. Discuss the implications of row echelon form for systems of linear equations and how Gaussian elimination can be used to solve such systems while computing the determinant. Additionally, demonstrate how Gaussian elimination can be used to compute the determinant of a singular matrix.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Consider the matrix \\( B = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 1 \\end{pmatrix} \\). Calculate the determinant of \\( B \\) and use it to determine the volume of the solid formed by the vectors corresponding to the rows of \\( B \\). Analyze the result geometrically and discuss the interpretation of the determinant in this context.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "(a) A skew-symmetric matrix satisfies \\( K^T = -K \\), as in\n    \\[\n    K = \\begin{bmatrix}\n    0 & a & b \\\\\n    -a & 0 & c \\\\\n    -b & -c & 0\n    \\end{bmatrix}.\n    \\]\n    In the 3 by 3 case, why is \\( \\det(-K) = (-1)^3 \\det K \\)? On the other hand \\( \\det K^T = \\det K \\) (always). Deduce that the determinant must be zero.\n\n    (b) Write down a 4 by 4 skew-symmetric matrix with \\( \\det K \\) not zero.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "$2x_1 + 3x_2 = 1$ \\quad and \\quad $4x_1 + 6x_2 = 1$. (parallel lines)",
            "equations": [
                "2x_1 + 3x_2 = 1",
                "4x_1 + 6x_2 = 1"
            ]
        },
        {
            "chapter": "Determinants",
            "question_latex": "Suppose the 4 by 4 matrix \\( M \\) has four equal rows all containing \\( a, b, c, d \\). We know that \\( \\det(M) = 0 \\). The problem is to find \\( \\det(I + M) \\) by any method:\n    \\[\n    \\det(I + M) =\n    \\begin{vmatrix}\n    1 + a & b & c & d \\\\\n    a & 1 + b & c & d \\\\\n    a & b & 1 + c & d \\\\\n    a & b & c & 1 + d\n    \\end{vmatrix}\n    \\]\n    Partial credit if you find this determinant when \\( a = b = c = d = 1 \\). Sudden death if you say that \\( \\det(I + M) = \\det I + \\det M \\).",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Let \\( A = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} \\). Calculate the determinant of \\( A \\) and classify the permutation of rows as even or odd. Provide a proof of your classification and explain how row exchanges affect the determinant in this case.",
            "equations": []
        },
        {
            "chapter": "Determinants",
            "question_latex": "Compute the determinants of \\( A \\), \\( B \\), and \\( C \\) from six terms. Are the rows independent?\n    \\[\n    A =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    3 & 1 & 2 \\\\\n    3 & 2 & 1\n    \\end{bmatrix},\n    \\quad\n    B =\n    \\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 4 & 4 \\\\\n    5 & 6 & 7\n    \\end{bmatrix},\n    \\quad\n    C =\n    \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    1 & 1 & 0 \\\\\n    1 & 0 & 0\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find a diagonal $M$, made up of $1$s and $-1$s, to show that\n    \\begin{itemize}",
            "equations": [
                "M",
                "1",
                "-1"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that the determinant equals the product of the eigenvalues by imagining that the characteristic polynomial is factored into\n    \\[\n    \\det(A - \\lambda I) = (\\lambda_1 - \\lambda)(\\lambda_2 - \\lambda) \\cdots (\\lambda_n - \\lambda),\n    \\]\n    and making a clever choice of $\\lambda$.\\",
            "equations": [
                "\\lambda"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "\\( P = \\begin{bmatrix} 1 & 2 \\\\ 1 & 2 \\end{bmatrix} \\)",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(b) Write its eigenvalues. If $Ax = \\lambda x$ then $e^{At}x = e^{\\lambda t} x$.\n    \\end{itemize}",
            "equations": [
                "Ax = \\lambda x",
                "e^{At}x = e^{\\lambda t} x"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "True or false: If the \\( n \\) columns of \\( S \\) (eigenvectors of \\( A \\)) are independent, then:\n    \\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "If the eigenvectors of \\( A \\) are the columns of \\( I \\), then \\( A \\) is a matrix. If the eigenvector matrix \\( S \\) is triangular, then \\( S^{-1} \\) is triangular and \\( A \\) is triangular.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find their conjugates and their absolute values.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find the distribution of the \\$4 trillion at year \\( k \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Write the 3 by 3 transition matrix for a chemistry course that is taught in two sections, if every week \\( \\frac{1}{4} \\) of those in Section A and \\( \\frac{1}{3} \\) of those in Section B drop the course, and \\( \\frac{1}{6} \\) of each section transfer to the other section.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that the total $v+w$ is constant (40 people).",
            "equations": [
                "v+w"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(e) A defective matrix (nondiagonalizable).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Every permutation matrix leaves $x = (1,1,...,1)$ unchanged. Then $\\lambda = 1$. Find two more eigenvalues for these permutations:\n    \\[\n    P_1 = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\end{bmatrix},\n    \\quad\n    P_2 = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix}.\n    \\]",
            "equations": [
                "x = (1,1,...,1)",
                "\\lambda = 1"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that \\( 3 \\times 3 \\) Hermitian matrices \\( A \\) and also unitary \\( U \\) have 9 real degrees of freedom (columns of \\( U \\) can be multiplied by any \\( e^{i\\theta} \\)).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(a) \\( A \\) is not invertible.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find the matrix in $\\frac{du}{dt} = Au$, and its eigenvalues and eigenvectors.",
            "equations": [
                "\\frac{du}{dt} = Au"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "When $P$ exchanges rows 1 and 2 and columns 1 and 2, the eigenvalues don\u2019t change.\n    Find eigenvectors of $A$ and $PAP$ for $\\lambda = 11$:\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 1 \\\\ 3 & 6 & 3 \\\\ 4 & 8 & 4 \\end{bmatrix}, \\quad\n    PAP = \\begin{bmatrix} 6 & 3 & 3 \\\\ 2 & 1 & 1 \\\\ 8 & 4 & 4 \\end{bmatrix}.\n    \\]",
            "equations": [
                "P",
                "A",
                "PAP",
                "\\lambda = 11"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "What values of \\( \\alpha \\) produce instability in\n    \\[\n    v_{n+1} = \\alpha (v_n + w_n), \\quad w_{n+1} = \\alpha (v_n + w_n)?\n    \\]",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(d) Under what conditions on \\( b \\) does \\( A x = b \\) have a solution?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Consider the transition matrix \\( P = \\begin{bmatrix} 0.7 & 0.3 & 0 \\\\ 0.2 & 0.6 & 0.2 \\\\ 0 & 0.5 & 0.5 \\end{bmatrix} \\). Find the steady-state vector by solving \\( P \\mathbf{v} = \\mathbf{v} \\). Then, determine the eigenvalue associated with the steady-state and explain its significance. Discuss the convergence properties of the Markov chain and the long-term behavior of the system, including any transient states if applicable.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that the second solution is $y = te^{3t}$.\n    \\end{itemize}",
            "equations": [
                "y = te^{3t}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "What are the limits as \\( k \\to \\infty \\) (the steady states) of the following?\n    \\[\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad\n    \\begin{pmatrix} 0.4 & 0.2 \\\\ 0.6 & 0.8 \\end{pmatrix}^k.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Which pairs are similar? Choose $a, b, c, d$ to prove that the other pairs aren\u2019t:\n    \\begin{itemize}",
            "equations": [
                "a, b, c, d"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The numbers \\( \\lambda_1^k \\) and \\( \\lambda_2^k \\) satisfy the Fibonacci rule\n    \\[\n    F_{k+2} = F_{k+1} + F_k,\n    \\]\n    where\n    \\[\n    \\lambda_{k+2}^1 = \\lambda_{k+1}^1 + \\lambda_k^1 \\quad \\text{and} \\quad \\lambda_{k+2}^2 = \\lambda_{k+1}^2 + \\lambda_k^2.\n    \\]\n    Prove this by using the original equation for the \\( \\lambda \\)\u2019s (multiply it by \\( \\lambda_k \\)). Then any combination of \\( \\lambda_1^k \\) and \\( \\lambda_2^k \\) satisfies the rule. The combination\n    \\[\n    F_k = \\frac{\\lambda_1^k - \\lambda_2^k}{\\lambda_1 - \\lambda_2}\n    \\]\n    gives the right start of \\( F_0 = 0 \\) and \\( F_1 = 1 \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Write $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 3 \\end{bmatrix}$ as $S\\Lambda S^{-1}$. Multiply $S e^{\\Lambda t} S^{-1}$ to find the matrix exponential $e^{At}$. Check $e^{At} = I$ when $t = 0$.",
            "equations": [
                "A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 3 \\end{bmatrix}",
                "S\\Lambda S^{-1}",
                "S e^{\\Lambda t} S^{-1}",
                "e^{At}",
                "e^{At} = I",
                "t = 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Diagonalize the Fibonacci matrix by completing \\( S^{-1} \\):\n    \\[\n    \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} \\lambda_1 & \\lambda_2 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix}.\n    \\]\n    Do the multiplication \\( S \\Lambda^k S^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\) to find its second component. This is the \\( k \\)-th Fibonacci number \\( F_k = \\frac{\\lambda_1^k - \\lambda_2^k}{\\lambda_1 - \\lambda_2} \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The vectors $v = (1,i,1)$, $w = (i,1,0)$ and $z = \\begin{bmatrix} a & b & c \\end{bmatrix}^T$ are an orthogonal basis for $\\mathbb{C}^n$.",
            "equations": [
                "v = (1,i,1)",
                "w = (i,1,0)",
                "z = \\begin{bmatrix} a & b & c \\end{bmatrix}^T",
                "\\mathbb{C}^n"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Suppose \\( A \\) has eigenvalues 1, 2, 4. What is the trace of \\( A^2 \\)? What is the determinant of \\( (A^{-1})^T \\)?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The trace of \\( S \\times \\Lambda S^{-1} \\) equals the trace of \\( \\Lambda S^{-1} \\times S \\). So the trace of a diagonalizable \\( A \\) equals the trace of \\( \\Lambda \\), which is \\underline{\\hspace{2cm}}.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find the eigenvalues of \\( A \\) and \\( B \\) and \\( A + B \\):\n    \\[\n    A = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}, \\quad A + B = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}.\n    \\]\n    Eigenvalues of \\( A + B \\) (are equal to) (are not equal to) eigenvalues of \\( A \\) plus eigenvalues of \\( B \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "$A = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix}$, $M = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta & 0 \\\\ \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$.",
            "equations": [
                "A = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix}",
                "M = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta & 0 \\\\ \\sin\\theta & \\cos\\theta & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find \\( \\Lambda \\) and \\( S \\) to diagonalize \\( B \\) in Problem 29. What is \\( B^{10} u_0 \\) for these \\( u_0 \\)?\n    \\[\n    u_0 = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}, \\quad u_0 = \\begin{pmatrix} 3 \\\\ -1 \\end{pmatrix}, \\quad u_0 = \\begin{pmatrix} 6 \\\\ 0 \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The product of two numbers on the unit circle?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Let \\( A = \\begin{bmatrix} 4 & 1 & 2 \\\\ 1 & 5 & 3 \\\\ 2 & 3 & 6 \\end{bmatrix} \\) be a symmetric matrix. Compute the eigenvalues and eigenvectors of \\( A \\), and diagonalize \\( A \\) by finding an orthogonal matrix \\( Q \\) such that \\( Q^T A Q = D \\), where \\( D \\) is the diagonal matrix of eigenvalues. Show that the matrix \\( A \\) is diagonalizable and explain the significance of the orthogonal transformation.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(c) $\\lambda +1$ is an eigenvalue of $A+I$, as in Problem 20.\n    \\end{itemize}",
            "equations": [
                "\\lambda +1",
                "A+I"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Give an example to show that the eigenvalues can be changed when a multiple of one row is subtracted from another. Why is a zero eigenvalue not changed by the steps of elimination?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Let \\( A = \\begin{bmatrix} 2 + i & 1 - i & 0 \\\\ 3 + 2i & 4 - i & 1 + i \\\\ 0 & 2 - i & 5 + i \\end{bmatrix} \\). Compute the eigenvalues and eigenvectors of \\( A \\), and determine whether the eigenvectors form an orthonormal basis with respect to the standard inner product in \\( \\mathbb{C}^3 \\). If not, apply the Gram-Schmidt process to obtain an orthonormal basis.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Which one starts with $y(0) = 1$ and $y'(0) = 0$?",
            "equations": [
                "y(0) = 1",
                "y'(0) = 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(d) \\( S \\) is diagonalizable.\n    \\end{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "On the space of $2 \\times 2$ matrices, let $T$ be the transformation that transposes every matrix. Find the eigenvalues and \"eigenmatrices\" for $A^T = \\lambda A$.",
            "equations": [
                "2 \\times 2",
                "T",
                "A^T = \\lambda A"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(F) \\( u_{n+1} - u_n = A u_n \\) or \\( u_{n+1} = (I + A) u_n \\) (this is Euler\u2019s method).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "$ \\frac{du}{dt} = Ju = \\begin{bmatrix} 5 & 1 \\\\ 0 & 5 \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} $ with initial value $ u(0) = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $.",
            "equations": [
                " \\frac{du}{dt} = Ju = \\begin{bmatrix} 5 & 1 \\\\ 0 & 5 \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} ",
                " u(0) = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} "
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "If $K^H = -K$ (skew-Hermitian), the eigenvalues are imaginary and the eigenvectors are orthogonal.\n    \\begin{itemize}",
            "equations": [
                "K^H = -K"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "For the complex numbers \\( 3 + 4i \\) and \\( 1 - i \\),\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "With the preceding \\( A \\), use elimination to solve \\( Ax = 0 \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(d) The eigenvalues of $(B+I)^{-1}$.\n    \\end{itemize}",
            "equations": [
                "(B+I)^{-1}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "A matrix with orthonormal eigenvectors has the form $A = U\\Lambda U^{-1} = U\\Lambda U^H$. Prove that $AA^H = A^H A$. These are exactly the normal matrices.",
            "equations": [
                "A = U\\Lambda U^{-1} = U\\Lambda U^H",
                "AA^H = A^H A"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(b) What are the other eigenvalues of \\( A \\) (and why)?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Suppose \\( A \\) and \\( B \\) have the same full set of eigenvectors, so that \\( A = S \\Lambda_1 S^{-1} \\) and \\( B = S \\Lambda_2 S^{-1} \\). Prove that \\( AB = BA \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(a) Write its inverse.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find the eigenvalues and eigenvectors for\n    \\[\n        \\frac{du}{dt} = Au = \\begin{bmatrix} 0 & 3 & 0 \\\\ -3 & 0 & 4 \\\\ 0 & -4 & 0 \\end{bmatrix} u.\n    \\]\n    Why do you know, without computing, that $e^{At}$ will be an orthogonal matrix and $||u(t)||^2 = u_1^2 + u_2^2 + u_3^2$ will be constant?",
            "equations": [
                "e^{At}",
                "||u(t)||^2 = u_1^2 + u_2^2 + u_3^2"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Let \\( A = \\begin{bmatrix} 4 & 1 & 0 & 0 \\\\ 0 & 4 & 1 & 0 \\\\ 0 & 0 & 4 & 1 \\\\ 0 & 0 & 0 & 4 \\end{bmatrix} \\). Find the eigenvalues of \\( A \\), and then compute the Jordan canonical form of \\( A \\). Determine whether \\( A \\) is diagonalizable, and if not, find the Jordan basis and describe the structure of the Jordan blocks.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Suppose that $\\lambda$ is an eigenvalue of $A$, and $x$ is its eigenvector: $Ax = \\lambda x$.\n    \\begin{enumerate}",
            "equations": [
                "\\lambda",
                "A",
                "x",
                "Ax = \\lambda x"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "\\( B = \\frac{1}{4} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{bmatrix} \\)\n    \\end{itemize}\n    Classes to check: Orthogonal, invertible, projection, permutation, Hermitian, rank-1, diagonalizable, Markov.\n    Find the eigenvalues of \\( A \\) and \\( B \\).",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "True or false, with a good reason:\n    \\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Which of these matrices cannot be diagonalized?\n    \\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Suppose $A$ has eigenvalues $0, 3, 5$ with independent eigenvectors $u, v, w$.\n    \\begin{enumerate}",
            "equations": [
                "A",
                "0, 3, 5",
                "u, v, w"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "\\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "There are six $3 \\times 3$ permutation matrices $P$. What numbers can be the determinants of $P$? What numbers can be pivots? What numbers can be the trace of $P$? What four numbers can be eigenvalues of $P$?",
            "equations": [
                "3 \\times 3",
                "P",
                "P",
                "P",
                "P"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "What is the limit as $k \\to \\infty$ (the Markov steady state) of\n    \\[\n    \\begin{bmatrix}\n    0.4 & 0.3 \\\\\n    0.6 & 0.7\n    \\end{bmatrix}^k\n    \\begin{bmatrix}\n    a \\\\\n    b\n    \\end{bmatrix}\n    ?\n    \\]",
            "equations": [
                "k \\to \\infty"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Consider the matrix \\( A = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix} \\). Find its eigenvalues and eigenvectors and show that \\( A \\) is not diagonalizable.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(b) The determinant of $B^T B$.",
            "equations": [
                "B^T B"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "If $A$ has eigenvalues 0 and 1, corresponding to the eigenvectors\n    \\[ \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\quad \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}, \\]\n    how can you tell in advance that $A$ is symmetric? What are its trace and determinant? What is $A$?",
            "equations": [
                " \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\quad \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}, ",
                "A",
                "A",
                "A"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "By direct multiplication, find $ J^2 $ and $ J^3 $ when $ J = \\begin{bmatrix} c & 1 \\\\ 0 & c \\end{bmatrix} $. Guess the form of $ J^k $. Set $ k = 0 $ to find $ J^0 $. Set $ k = -1 $ to find $ J^{-1} $.",
            "equations": [
                " J^2 ",
                " J^3 ",
                " J = \\begin{bmatrix} c & 1 \\\\ 0 & c \\end{bmatrix} ",
                " J^k ",
                " k = 0 ",
                " J^0 ",
                " k = -1 ",
                " J^{-1} "
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find three $2 \\times 2$ matrices that have $\\lambda_1 = \\lambda_2 = 0$. The trace is zero and the determinant is zero. The matrix $A$ might not be 0 but check that $A^2 = 0$.",
            "equations": [
                "2 \\times 2",
                "\\lambda_1 = \\lambda_2 = 0",
                "A",
                "A^2 = 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "For a circulant $C = F \\Lambda F^{-1}$, why is it faster to multiply by $F^{-1}$, then $\\Lambda$, then $F$ (the convolution rule), than to multiply directly by $C$?",
            "equations": [
                "C = F \\Lambda F^{-1}",
                "F^{-1}",
                "\\Lambda",
                "F",
                "C"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "If $P$ is the matrix that projects $\\mathbb{R}^n$ onto a subspace $S$, explain why every vector in $S$ is an eigenvector, and so is every vector in $S^{\\perp}$. What are the eigenvalues? (Note the connection to $P^2 = P$, which means that $\\lambda^2 = \\lambda$.)",
            "equations": [
                "P",
                "\\mathbb{R}^n",
                "S",
                "S",
                "S^{\\perp}",
                "P^2 = P",
                "\\lambda^2 = \\lambda"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(a) \\( A \\) is invertible.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The (complex) dimension of $\\mathbb{C}^n$ is $n$. Find a nonreal basis for $\\mathbb{C}^n$.",
            "equations": [
                "\\mathbb{C}^n",
                "n",
                "\\mathbb{C}^n"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "In the list below, which classes of matrices contain \\( A \\) and which contain \\( B \\)?\n    \\begin{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(c) not diagonalizable.\n    \\end{itemize}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "A diagonal matrix like $\\Lambda = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}$ satisfies the usual rule $e^{\\Lambda(t+T)} = e^{\\Lambda t} e^{\\Lambda T}$, because the rule holds for each diagonal entry.\n    \n    \\begin{itemize}",
            "equations": [
                "\\Lambda = \\begin{bmatrix} 1 & 0 \\\\ 0 & 2 \\end{bmatrix}",
                "e^{\\Lambda(t+T)} = e^{\\Lambda t} e^{\\Lambda T}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The eigenvalues of \\( A \\) are 1 and 9, and the eigenvalues of \\( B \\) are \\( -1 \\) and 9:\n    \\[\n    A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix}, \\quad\n    B = \\begin{pmatrix} 4 & 5 \\\\ 5 & 4 \\end{pmatrix}.\n    \\]\n    Find a matrix square root of \\( A \\) from \\( R = S \\sqrt{\\Lambda} S^{-1} \\). Why is there no real matrix square root of \\( B \\)?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Diagonalize the $2 \\times 2$ skew-Hermitian matrix \n    \\[\n    K = \\begin{bmatrix} i & i \\\\ i & i \\end{bmatrix},\n    \\]\n    whose entries are all $\\sqrt{-1}$. Compute $e^{Kt} = S e^{\\Lambda t} S^{-1}$, and verify that $e^{Kt}$ is unitary. What is the derivative of $e^{Kt}$ at $t = 0$?",
            "equations": [
                "2 \\times 2",
                "\\sqrt{-1}",
                "e^{Kt} = S e^{\\Lambda t} S^{-1}",
                "e^{Kt}",
                "e^{Kt}",
                "t = 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(b) \\( A \\) is diagonalizable.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "If \\( A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\) and \\( AB = BA \\), show that \\( B = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\) is also diagonal. \\( B \\) has the same eigen\\underline{\\hspace{2cm}} as \\( A \\), but different eigen\\underline{\\hspace{2cm}}. These diagonal matrices \\( B \\) form a two-dimensional subspace of matrix space. \\( AB - BA = 0 \\) gives four equations for the unknowns \\( a, b, c, d \\)\u2014find the rank of the \\( 4 \\times 4 \\) matrix.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Generally, $e^A e^B$ is different from $e^B e^A$. They are both different from $e^{A+B}$. Check this using Problems 36--37 and 34:\n    \\begin{itemize}",
            "equations": [
                "e^A e^B",
                "e^B e^A",
                "e^{A+B}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Prove that the inverse of a Hermitian matrix is again a Hermitian matrix.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Suppose each \u201cGibonacci\u201d number \\( G_{k+2} \\) is the average of the two previous numbers, \\( G_{k+1} \\) and \\( G_k \\). Then\n    \\[\n    G_{k+2} = \\frac{1}{2} (G_{k+1} + G_k) = \\frac{1}{2} G_{k+1} + \\frac{1}{2} G_k.\n    \\]\n    This can be written as\n    \\[\n    \\begin{pmatrix} G_{k+2} \\\\ G_{k+1} \\end{pmatrix} = A \\begin{pmatrix} G_{k+1} \\\\ G_k \\end{pmatrix},\n    \\]\n    where \\( A \\) is the transformation matrix.\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that the trace equals the sum of the eigenvalues, in two steps. First, find the coefficient of $(-\\lambda)^{n-1}$ on the right side of equation (16). Next, find all the terms in \n    \\[\n    \\det(A - \\lambda I) = \\det\n    \\begin{bmatrix}\n    a_{11} - \\lambda & a_{12} & \\cdots & a_{1n} \\\\\n    a_{21} & a_{22} - \\lambda & \\cdots & a_{2n} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    a_{n1} & a_{n2} & \\cdots & a_{nn} - \\lambda\n    \\end{bmatrix}\n    \\]\n    that involve $(-\\lambda)^{n-1}$. They all come from the main diagonal! Find that coefficient of $(-\\lambda)^{n-1}$ and compare.",
            "equations": [
                "(-\\lambda)^{n-1}",
                "(-\\lambda)^{n-1}",
                "(-\\lambda)^{n-1}"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Let \\( P = \\begin{bmatrix} 0.8 & 0.2 \\\\ 0.1 & 0.9 \\end{bmatrix} \\) represent the transition matrix of a Markov chain. Compute the steady-state vector \\( \\mathbf{v} \\) that satisfies \\( P \\mathbf{v} = \\mathbf{v} \\), and determine the eigenvalue and eigenvector corresponding to this steady state. Analyze how the steady-state distribution evolves over multiple iterations and provide an explanation of the convergence process to the steady state.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Figure out how to write $my'' + by' + ky = 0$ as a vector equation $Mu' = Au$.",
            "equations": [
                "my'' + by' + ky = 0",
                "Mu' = Au"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The functions $e^{-ix}$ and $e^{-ix}$ are orthogonal on the interval $0 \\leq x \\leq 2\\pi$ because their complex inner product is $\\int_0^{2\\pi} e^{-ix} e^{ix}dx = 0$.",
            "equations": [
                "e^{-ix}",
                "e^{-ix}",
                "0 \\leq x \\leq 2\\pi",
                "\\int_0^{2\\pi} e^{-ix} e^{ix}dx = 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Diagonalize the matrix \\( A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix} \\) and find one of its square roots\u2014a matrix such that \\( R^2 = A \\). How many square roots will there be?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "The solution to $y'' = 0$ is a straight line $y = C +Dt$. Convert to a matrix equation:\n    \\begin{itemize}",
            "equations": [
                "y'' = 0",
                "y = C +Dt"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Find a third column so that $U$ is unitary. How much freedom in column 3?\n    \\[\n    U = \\begin{bmatrix} \n    \\frac{1}{\\sqrt{3}} & \\frac{i}{\\sqrt{2}} \\\\\n    \\frac{1}{\\sqrt{3}} & 0 \\\\\n    \\frac{i}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} \n    \\end{bmatrix}.\n    \\]",
            "equations": [
                "U"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(a) If \\( A^2 = I \\), what are the possible eigenvalues of \\( A \\)?\n    \n    (b) If this \\( A \\) is 2 by 2, and not \\( I \\) or \\( -I \\), find its trace and determinant.\n    \n    (c) If the first row is \\( (3, -1) \\), what is the second row?",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "$\\lambda_1 < 0$ and $\\lambda_2 > 0$.",
            "equations": [
                "\\lambda_1 < 0",
                "\\lambda_2 > 0"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Let \\( P = \\begin{bmatrix} 0.5 & 0.5 & 0 \\\\ 0.2 & 0.3 & 0.5 \\\\ 0.3 & 0.2 & 0.5 \\end{bmatrix} \\) be a transition matrix of a Markov chain. Determine the steady-state vector \\( \\mathbf{v} \\) that satisfies \\( P \\mathbf{v} = \\mathbf{v} \\). Solve for the eigenvalue and eigenvector associated with the steady-state, and interpret the meaning of the result in the context of the long-term behavior of the chain.",
            "equations": []
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "(a) Show that $Pu = u$. Then $u$ is an eigenvector with $\\lambda = 1$.",
            "equations": [
                "Pu = u",
                "u",
                "\\lambda = 1"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Show that every matrix of order $> 1$ is the sum of two singular matrices.",
            "equations": [
                "> 1"
            ]
        },
        {
            "chapter": "Eigenvalues and Eigenvectors",
            "question_latex": "Diagonalize this orthogonal matrix to reach $Q = U \\Lambda U^H$. Now all $\\lambda$\u2019s are:\n    \\[\n    Q = \\begin{bmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{bmatrix}.\n    \\]",
            "equations": [
                "Q = U \\Lambda U^H",
                "\\lambda"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Consider a game theory problem in which two players, Player 1 and Player 2, have the following payoff matrices:\n\n    Player 1's payoff matrix:\n    \\[\n    \\begin{matrix}\n    2 & -1 \\\\\n    4 & 3\n    \\end{matrix}\n    \\]\n\n    Player 2's payoff matrix:\n    \\[\n    \\begin{matrix}\n    3 & 2 \\\\\n    1 & -2\n    \\end{matrix}\n    \\]\n\n    Find the mixed strategy Nash equilibrium using linear programming. Determine the probabilities with which each player should choose their strategies to maximize their respective payoffs.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss the concept of a dominant strategy in game theory. Provide an example of a game where one player has a dominant strategy and explain how the existence of a dominant strategy affects the outcome of the game.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Apply the dual simplex method to solve the following linear programming problem:\n\n    Minimize \\( Z = 2x_1 + 3x_2 \\)\n\n    subject to the constraints:\n    \\[\n    2x_1 + x_2 \\geq 6\n    \\]\n    \\[\n    x_1 + 3x_2 \\geq 8\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "The maximal flow problem has slack variables $w_{ij} = c_{ij} - x_{ij}$ for the difference between capacities and flows. State the problem of Figure 8.5 as a linear program.",
            "equations": [
                "w_{ij} = c_{ij} - x_{ij}"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "If the primal problem is constrained by equations instead of inequalities\u2014Minimize \\( cx \\) subject to \\( Ax = b \\) and \\( x \\geq 0 \\)\u2014then the requirement \\( y \\geq 0 \\) is left out of the dual: Maximize \\( yb \\) subject to \\( yA \\leq c \\). Show that the one-sided inequality \\( yb \\leq cx \\) still holds. Why was \\( y \\geq 0 \\) needed in equation (1) but not here? This weak duality can be completed to full duality.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Draw a 5-node network with capacity $|i - j|$ between node $i$ and node $j$. Find the largest possible flow from node 1 to node 4.",
            "equations": [
                "|i - j|",
                "i",
                "j"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Find the Nash equilibrium for a game in which Player A can choose between $S_1$ and $S_2$, and Player B can choose between $T_1$ and $T_2$, with the following payoff matrix:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (2, 2) & (3, 1) \\\\\n    S_2 & (1, 3) & (4, 4) \\\\\n    \\end{matrix}\n    \\]",
            "equations": [
                "S_1",
                "S_2",
                "T_1",
                "T_2"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "How many lines (horizontal and vertical) are needed to cover all the 1s in $A$ in Problem 4? For any matrix, explain why weak duality is true: If $k$ marriages are possible, then it takes at least $k$ lines to cover all the 1s.",
            "equations": [
                "A",
                "k",
                "k"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "How will the optimal strategies in the game that opens this section be affected if the \\$20 is increased to \\$70? What is the value (the average win for X) of this new game?",
            "equations": [
                "20 is increased to \\"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Apply game theory to analyze the behavior of firms in a price war. Assume two firms are competing on prices, and use game theory to find the Nash equilibrium in the pricing game. Discuss how the equilibrium price affects both firms' profits.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss the steps involved in converting a linear inequality into an equation using slack variables. Provide a detailed example to illustrate this process, including the conversion of inequalities into equalities for optimization problems.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Phase I finds a basic feasible solution to $Ax = b$ (a corner). After changing signs to make $b \\geq 0$, consider the auxiliary problem of minimizing $w_1 + w_2 + \\cdots + w_m$, subject to $x \\geq 0$, $w \\geq 0$, $Ax + w = b$. Whenever $Ax = b$ has a nonnegative solution, the minimum cost in this problem will be zero\u2014with $w^* = 0$.\n    \\begin{itemize}",
            "equations": [
                "Ax = b",
                "b \\geq 0",
                "w_1 + w_2 + \\cdots + w_m",
                "x \\geq 0",
                "w \\geq 0",
                "Ax + w = b",
                "Ax = b",
                "w^* = 0"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Draw a 5-node network with capacity $|i - j|$ between node $i$ and node $j$. Find the largest possible flow from node 1 to node 4.",
            "equations": [
                "|i - j|",
                "i",
                "j"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "If \\( a_{ij} \\) is the largest entry in its row and the smallest in its column, why will X always choose column j and Y always choose row i (regardless of the rest of the matrix)? Show that the preceding problem had such an entry, and then construct an \\( A \\) without one.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Starting with the 2 by 2 matrix \\( A =\n    \\begin{pmatrix}\n    1 & 0 \\\\\n    0 & -1\n    \\end{pmatrix} \\), choose \\( b \\) and \\( c \\) so that both of the feasible\n    sets \\( Ax \\geq b \\), \\( x \\geq 0 \\) and \\( yA \\leq c \\), \\( y \\geq 0 \\) are empty.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Formulate the following problem as a linear programming problem: A company has 3 types of workers: Senior, Junior, and Trainee. Each worker can produce a certain number of units of a product per day as follows:\n\n    \\[\n    \\text{Senior:} \\quad 10 \\text{ units per day}\n    \\]\n    \\[\n    \\text{Junior:} \\quad 8 \\text{ units per day}\n    \\]\n    \\[\n    \\text{Trainee:} \\quad 5 \\text{ units per day}\n    \\]\n\n    The company needs to produce at least 300 units per day. Senior workers are paid $50 per day, Junior workers $30 per day, and Trainees $20 per day. The company wants to minimize the total cost while satisfying the production requirement. Formulate this as a linear programming problem.",
            "equations": [
                "50 per day, Junior workers "
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve a mixed strategy game where both players have two strategies and the payoffs are non-symmetric. Use the linear programming method to derive the mixed strategy Nash equilibrium and explain the significance of each player's mixed strategy.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "What shape is the feasible set \\( x \\geq 0 \\), \\( y \\geq 0 \\), \\( z \\geq 0 \\), \\( x + y + z = 1 \\), and what is the maximum of \\( x + 2y + 3z \\)?",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Why does the greedy algorithm work for the spanning tree problem?",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "For the matrix $A$ in Problem 4, which rows violate Hall\u2019s condition by having all their 1s in too few columns? Which $p \\times q$ submatrix of zeros has $p + q > n$?",
            "equations": [
                "A",
                "p \\times q",
                "p + q > n"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "(Transportation problem) Suppose Texas, California, and Alaska each produce a million barrels of oil; 800,000 barrels are needed in Chicago at a distance of 1000, 2000, and 3000 miles from the three producers, respectively; and 2,200,000 barrels are needed in New England 1500, 3000, and 3700 miles away. If shipments cost one unit for each barrel-mile, what linear program with five equality constraints must be solved to minimize the shipping cost?",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Explain the role of linear inequalities in multi-objective optimization problems. How do these inequalities help in identifying a solution that balances multiple objectives? Provide an example.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive the Nash equilibrium for a coordination game with two players. Provide a numerical example of a coordination game where the players can either cooperate or defect, and show the different possible Nash equilibria in this game.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "On the preceding feasible set, what is the minimum value of the cost function \\( x + y \\)? Draw the line \\( x + y = \\text{constant} \\) that first touches the feasible set. What points minimize the cost functions \\( 3x + y \\) and \\( x - y \\)?",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "How can linear inequalities be used to model transportation problems in logistics? Formulate a system of inequalities to represent supply and demand constraints and solve for the optimal transportation plan.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "If Figure 8.5 shows lengths instead of capacities, find the shortest path from $s$ to $t$, and a minimal spanning tree.",
            "equations": [
                "s",
                "t"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "In the context of a diet problem, formulate a set of linear inequalities to represent nutritional constraints such as calorie, protein, and fat intake. Solve the inequalities graphically to determine the feasible diet plan.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Given the system of inequalities, \\(x + 2y \\leq 5\\), \\(3x - y \\geq 4\\), and \\(x \\geq 0\\), graphically represent the feasible region and discuss how the feasible solutions are constrained by these inequalities.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive the solution to a zero-sum game with mixed strategies and explain how linear programming can be used to solve the game. Provide a specific 3x3 payoff matrix and solve for the mixed strategy equilibrium.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Minimize $x_1 + x_2 - x_3$, subject to:\n    \\begin{align*}\n        2x_1 - 4x_2 + x_3 + x_4 &= 4, \\\\\n        3x_1 + 5x_2 + x_3 + x_5 &= 2.\n    \\end{align*}\n    Which of $x_1$, $x_2$, $x_3$ should enter the basis, and which of $x_4$, $x_5$ should leave? Compute the new pair of basic variables, and find the cost at the new corner.",
            "equations": [
                "x_1 + x_2 - x_3",
                "x_1",
                "x_2",
                "x_3",
                "x_4",
                "x_5"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Suppose $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$. What weights $x_1$ and $1 - x_1$ will give a column of the form $\\begin{pmatrix} u \\\\ u \\end{pmatrix}$, and what weights $y_1$ and $1 - y_1$ on the two rows will give a new row $[v \\; v]$? \\\\ show that  v=u",
            "equations": [
                "A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}",
                "x_1",
                "1 - x_1",
                "\\begin{pmatrix} u \\\\ u \\end{pmatrix}",
                "y_1",
                "1 - y_1",
                "[v \\; v]"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "If all entries of \\( A \\), \\( b \\), and \\( c \\) are positive, show that both the primal and the dual are\n    feasible.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive the Nash equilibrium for a public goods game where players must decide how much to contribute to the provision of a public good. Explain the challenges of finding a cooperative solution in this game and discuss the implications for social welfare.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Using the graphical method, solve the following system of inequalities: \\(4x + y \\leq 12\\), \\(x - 2y \\geq 3\\), and \\(x \\geq 0\\). Identify the feasible region and determine the optimal solution for \\(z = 2x + 3y\\).",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve for the Nash equilibrium in a game with incomplete information. Given a game where players have private information about their payoffs, use the Bayesian Nash equilibrium concept to derive the optimal strategies for each player.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Explain how artificial variables are used in the Simplex Method to handle linear programming problems that do not start with an initial basic feasible solution. Provide an example where artificial variables are required and explain how they are removed during the solution process.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve the following primal-dual pair of problems:\n    \\[\n    \\text{Maximize } z = 4x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 6, \\quad 2x_1 + x_2 \\geq 5, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 6y_1 + 5y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + 2y_2 \\geq 4, \\quad y_1 + y_2 \\leq 3, \\quad y_1 \\geq 0, \\quad y_2 \\geq 0.\n    \\]\n    Verify the duality conditions and interpret the solutions in terms of the primal and dual variables.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Show that the strong duality theorem holds for the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 7x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 6, \\quad x_1 + 3x_2 \\geq 5, \\quad x_1, x_2 \\geq 0.\n    \\]\n    Derive the dual problem and prove that the optimal values of the primal and dual problems are equal.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss the role of mixed strategies in game theory. Derive the mixed strategy Nash equilibrium for a simple game, such as the game of matching pennies, and explain the significance of randomization in players' strategies.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve the following linear programming problem using the Simplex Method:\n    \\[\n    \\text{Maximize } z = 2x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + y \\leq 4, \\quad x + 2y \\leq 6, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Construct the initial tableau and explain the steps for identifying the entering and leaving variables. Demonstrate the pivoting process and discuss the final optimal solution.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "a set of columns with 1s in too few rows.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive and solve a transportation problem with fixed supply and demand quantities using the primal-dual method. Provide a specific example with supply, demand, and cost matrices, and show how the primal-dual method helps achieve the optimal solution.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve the following primal and dual problems simultaneously and verify the duality conditions:\n    \\[\n    \\text{Maximize } z = 5x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 4, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1, x_2 \\geq 0,\n    \\]\n    and\n    \\[\n    \\text{Minimize } w = 4y_1 + 6y_2\n    \\]\n    subject to the constraints\n    \\[\n    y_1 + 2y_2 \\geq 5, \\quad y_1 + y_2 \\leq 3, \\quad y_1, y_2 \\geq 0.\n    \\]\n    Verify that the primal-dual solutions satisfy the duality conditions.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss how the concept of duality applies to the transportation problem. Provide a numerical example and formulate both the primal and dual problems. Solve both problems and verify the duality theorem by comparing the objective values.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Show that the following problem is feasible but unbounded, so it has no optimal solution: Maximize \\( x + y \\), subject to \\( x \\geq 0 \\), \\( y \\geq 0 \\), \\( -3x + 2y \\leq -1 \\), \\( x - y \\leq 2 \\).",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Apply the Ford-Fulkerson method to a maximum flow problem where the capacity of each edge is an integer. Provide a flow network with 5 nodes and 6 edges, and solve for the maximum flow from the source to the sink.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Explain the concept of mixed strategy equilibria in zero-sum games. Derive the mixed strategy Nash equilibrium for a zero-sum game with two players, where each player has two strategies, and solve the corresponding linear programming problem.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Consider the linear programming problem: \n    \\[\n    \\text{Minimize } z = -2x + 3y\n    \\]\n    subject to the constraints\n    \\[\n    x + 2y \\geq 4, \\quad 3x - y \\leq 5, \\quad x \\geq 0, \\quad y \\geq 0.\n    \\]\n    Solve this problem using the Simplex Method, starting from the initial tableau. Include all steps of the algorithm, including the pivoting process and optimality check.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Find the mixed strategy Nash equilibrium for the following game, where Player A has strategies $S_1$, $S_2$, and $S_3$, and Player B has strategies $T_1$ and $T_2$:\n\n    \\[\n    \\begin{matrix}\n      & T_1 & T_2 \\\\\n    S_1 & (1, -1) & (3, -3) \\\\\n    S_2 & (4, -4) & (2, -2) \\\\\n    S_3 & (0, 0) & (5, -5) \\\\\n    \\end{matrix}\n    \\]",
            "equations": [
                "S_1",
                "S_2",
                "S_3",
                "T_1",
                "T_2"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Prove the strong duality theorem in linear programming. Provide a detailed proof showing that if the primal problem has an optimal solution, then the dual problem also has an optimal solution, and vice versa.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive the complementary slackness conditions for the following linear programming problem:\n    \\[\n    \\text{Maximize } z = 4x_1 + 3x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + x_2 \\leq 5, \\quad 2x_1 + x_2 \\geq 6, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Explain the significance of the complementary slackness conditions and provide an interpretation in terms of the dual variables.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Define a Nash equilibrium in the context of game theory. Discuss its significance and provide an example of a game where players have conflicting interests. Solve for the Nash equilibrium in a two-player game with a 3x3 payoff matrix, explaining the steps involved in the process.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Derive the conditions for a Nash equilibrium in a two-player game where both players have two strategies. Use a 2x2 matrix to demonstrate how to find the equilibrium and explain the conditions under which the game has a pure strategy Nash equilibrium.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Given the following game matrix, where the players choose between strategies $X$ and $Y$, compute the mixed strategy Nash equilibrium:\n\n    \\[\n    \\begin{matrix}\n      & X & Y \\\\\n    X & (1, 1) & (2, 3) \\\\\n    Y & (3, 2) & (0, 4) \\\\\n    \\end{matrix}\n    \\]",
            "equations": [
                "X",
                "Y"
            ]
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Using the simplex method, solve the following linear programming problem: maximize \\(z = 3x + 4y\\), subject to the constraints \\(x + 2y \\leq 6\\), \\(2x + y \\leq 6\\), and \\(x, y \\geq 0\\).",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Apply Dijkstra's algorithm to find the shortest path from node A to node B in a graph with 7 nodes and weighted edges. Provide the step-by-step calculation and verify the correctness of the solution.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Apply the primal-dual interior-point method to solve the following linear programming problem:\n\n    Maximize \\( Z = 2x_1 + 3x_2 \\)\n\n    subject to:\n    \\[\n    3x_1 + 2x_2 \\leq 10\n    \\]\n    \\[\n    x_1 + 2x_2 \\geq 4\n    \\]\n    \\[\n    x_1, x_2 \\geq 0\n    \\]",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss the concept of the prisoners' dilemma in the context of game theory. Provide a detailed explanation of the game and solve for the Nash equilibrium. Analyze the social and economic consequences of the equilibrium strategy in a real-world scenario.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Use the simplex method to solve a transportation problem with a non-degenerate solution. Provide a specific numerical example and explain the steps in the simplex algorithm, including the initialization of the basic feasible solution and the optimality condition.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Solve for the Nash equilibrium in a sequential game using backward induction. Consider a game where two players move in turn, and each player must decide their strategy based on the previous player's move. Explain the process of backward induction to find the equilibrium strategy.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Consider the following primal problem:\n    \\[\n    \\text{Minimize } w = 3x_1 + 4x_2\n    \\]\n    subject to the constraints\n    \\[\n    x_1 + 2x_2 \\geq 5, \\quad 2x_1 + x_2 \\leq 7, \\quad x_1 \\geq 0, \\quad x_2 \\geq 0.\n    \\]\n    Derive the dual problem and solve the primal and dual problems. Verify the optimality conditions and interpret the solutions.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Define and explain the concept of a mixed strategy Nash equilibrium. Derive the mixed strategy Nash equilibrium for a 2x2 game matrix, where each player has two strategies. Provide a detailed step-by-step solution, including the probabilities associated with each strategy.",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Suppose \\( A \\) is the identity matrix (so that \\( m = n \\)), and the vectors \\( b \\) and \\( c \\) are nonnegative. Explain why \\( x^* = b \\) is optimal in the minimum problem, find \\( y^* \\) in the maximum problem, and verify that the two values are the same. If the first component of \\( b \\) is negative, what are \\( x^* \\) and \\( y^* \\)?",
            "equations": []
        },
        {
            "chapter": "Linear Programming and Game Theory",
            "question_latex": "Discuss the geometric interpretation of the simplex method in the context of linear inequalities. How does the method move from one vertex of the feasible region to another to find the optimal solution?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Follow the 3 by 3 text example but with plus signs in $A$. Eliminate above and below the pivots to reduce $[A \\ I]$ to $[I \\ A^{-1}]$:\n    \\[\n    \\begin{bmatrix} 2 & 1 & 0 & 1 & 0 & 0 \\\\ 1 & 2 & 1 & 0 & 1 & 0 \\\\ 0 & 1 & 2 & 0 & 0 & 1 \\end{bmatrix}.\n    \\]",
            "equations": [
                "A",
                "[A \\ I]",
                "[I \\ A^{-1}]"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "The matrix that rotates the $ x-y $ plane by an angle $ \\theta $ is\n    $$A(\\theta) = \\begin{pmatrix}     \\cos \\theta & -\\sin \\theta \\\\     \\sin \\theta & \\cos \\theta     \\end{pmatrix}.$$\n    Verify that $ A(\\theta_1)A(\\theta_2) = A(\\theta_1 + \\theta_2) $ from the identities for $ \\cos(\\theta_1 + \\theta_2) $ and $ \\sin(\\theta_1 + \\theta_2) $. What is $ A(\\theta) $ times $ A(-\\theta) $?",
            "equations": [
                " x-y ",
                " \\theta ",
                "",
                "",
                " A(\\theta_1)A(\\theta_2) = A(\\theta_1 + \\theta_2) ",
                " \\cos(\\theta_1 + \\theta_2) ",
                " \\sin(\\theta_1 + \\theta_2) ",
                " A(\\theta) ",
                " A(-\\theta) "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$M = A - UW^{-1}V$ and $M^{-1} = A^{-1} + A^{-1} U(W - V A^{-1} U)^{-1} V A^{-1}$.\n    \\end{itemize}",
            "equations": [
                "M = A - UW^{-1}V",
                "M^{-1} = A^{-1} + A^{-1} U(W - V A^{-1} U)^{-1} V A^{-1}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Find the inverses (directly or from the $2 \\times 2$ formula) of $A$, $B$, $C$:\n    \\[\n    A = \\begin{bmatrix} 0 & 3 \\\\ 4 & 6 \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix} a & b \\\\ b & 0 \\end{bmatrix}, \\quad\n    C = \\begin{bmatrix} 3 & 4 \\\\ 5 & 7 \\end{bmatrix}.\n    \\]",
            "equations": [
                "2 \\times 2",
                "A",
                "B",
                "C"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "All entries are whole numbers.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "When $b = (2,5,7)$, find a solution $(u,v,w)$ to equation (4) different from the solution $(1,0,1)$ mentioned in the text.",
            "equations": [
                "b = (2,5,7)",
                "(u,v,w)",
                "(1,0,1)"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Show that $L^{-1}$ has entries $j/i$ for $i \\leq j$ for the given matrix $L$:\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    -\\frac{1}{2} & 1 & 0 & 0 \\\\\n    0 & -\\frac{2}{3} & 1 & 0 \\\\\n    0 & 0 & -\\frac{3}{4} & 1\n    \\end{bmatrix}\n    \\]\n    \n    \\[\n    L^{-1} = \\begin{bmatrix}\n    1 & 0 & 0 & 0 \\\\\n    \\frac{1}{2} & 1 & 0 & 0 \\\\\n    \\frac{1}{3} & \\frac{2}{3} & 1 & 0 \\\\\n    \\frac{1}{4} & \\frac{2}{4} & \\frac{3}{4} & 1\n    \\end{bmatrix}\n    \\]\n    \n    \\begin{itemize}",
            "equations": [
                "L^{-1}",
                "j/i",
                "i \\leq j",
                "L"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "How many entries can be chosen independently in a skew-symmetric matrix \\( (K^T = -K) \\) of order \\( n \\)? The diagonal of \\( K \\) is zero!",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "The \\(n \\times n\\) permutation matrices are an important example of a \u201cgroup.\u201d If you multiply them you stay inside the group; they have inverses in the group; the identity is in the group; and the law \\(P_1(P_2P_3) = (P_1P_2)P_3\\) is true\u2014because it is true for all matrices.\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Give examples of \\( A \\) and \\( B \\) such that\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "For the system\n    \\begin{align*}\n    u + v + w &= 2 \\\\\n    u + 3v + 3w &= 0 \\\\\n    u + 3v + 5w &= 2,\n    \\end{align*}\n    what is the triangular system after forward elimination, and what is the solution?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "the new entry that replaces $ a_{ij} $ after that subtraction.",
            "equations": [
                " a_{ij} "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Invent two more matrix groups.\n    \\end{itemize}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "There are sixteen 2 by 2 matrices whose entries are 1s and \u22121s. How many are invertible?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$AB$",
            "equations": [
                "AB"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "\\(A^{-1} = A^T\\),",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If \\(E\\) is 2 by 2 and it adds the first equation to the second, what are \\(E^2\\), \\(E^8\\), and \\(8E\\)?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Solve the triangular system \\( Lc = b \\) to find \\( c \\). Then solve \\( Ux = c \\) to find \\( x \\):\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 \\\\\n    4 & 1\n    \\end{bmatrix},\n    \\quad\n    U = \\begin{bmatrix}\n    2 & 4 \\\\\n    0 & 1\n    \\end{bmatrix},\n    \\quad\n    b = \\begin{bmatrix}\n    2 \\\\\n    11\n    \\end{bmatrix}.\n    \\]\n    For safety, find \\( A = LU \\) and solve \\( Ax = b \\) as usual. Circle \\( c \\) when you see it.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "A $4 \\times 4$ matrix with a row of zeros is not invertible.",
            "equations": [
                "4 \\times 4"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Show that $A = 4 \\cdot I_4 - \\mathbf{1}_{4,4}$ is not invertible: Multiply $A \\cdot \\mathbf{1}_{4,1}$.",
            "equations": [
                "A = 4 \\cdot I_4 - \\mathbf{1}_{4,4}",
                "A \\cdot \\mathbf{1}_{4,1}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Reflect every vector through the 45\u00b0 line \\( x_1 = x_2 \\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$AB$ has columns $Ab_1, ..., Ab_n$, and $Bc$ has one column $c_1b_1 + \\cdots + c_n b_n$.",
            "equations": [
                "AB",
                "Ab_1, ..., Ab_n",
                "Bc",
                "c_1b_1 + \\cdots + c_n b_n"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If every row of a $4 \\times 4$ matrix contains the numbers $0, 1, 2, 3$ in some order:\n    \\begin{itemize}",
            "equations": [
                "4 \\times 4",
                "0, 1, 2, 3"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$A(B+C)$",
            "equations": [
                "A(B+C)"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "What multiple $k$ of equation 1 should be subtracted from equation 2?\n    \\begin{align*}\n    ax + by &= f \\\\\n    cx + dy &= g.\n    \\end{align*}\n    The first pivot is $a$ (assumed nonzero). Elimination produces what formula for the second pivot? What is $y$? The second pivot is missing when $ad = bc$.",
            "equations": [
                "k",
                "a",
                "y",
                "ad = bc"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "(Second proof of $A = LU$) The third row of $U$ comes from the third row of $A$ by subtracting multiples of rows 1 and 2 (of $U$!):\n    \\[\n    \\text{row 3 of } U = \\text{row 3 of } A - \\ell_{31}(\\text{row 1 of } U) - \\ell_{32}(\\text{row 2 of } U).\n    \\]\n    \\begin{enumerate}",
            "equations": [
                "A = LU",
                "U",
                "A",
                "U"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "For the matrices \n    \\[\n    A = \\begin{bmatrix} 1 & 0 \\\\ 2 & 1 \\end{bmatrix} \\quad \\text{and} \\quad B = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix},\n    \\]\n    compute \\(AB\\), \\(BA\\), \\(A^{-1}\\), \\(B^{-1}\\), and \\((AB)^{-1}\\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "For which three numbers $c$ is this matrix not invertible, and why not?\n    \\[\n    A = \\begin{bmatrix} 2 & c & c \\\\ c & c & c \\\\ 8 & 7 & c \\end{bmatrix}.\n    \\]",
            "equations": [
                "c"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If an $ m \\times n $ matrix $ A $ multiplies an $ n $-dimensional vector $ x $, how many separate multiplications are involved? What if $ A $ multiplies an $ n \\times p $ matrix $ B $?",
            "equations": [
                " m \\times n ",
                " A ",
                " n ",
                " x ",
                " A ",
                " n \\times p ",
                " B "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "This matrix has a remarkable inverse. Find $A^{-1}$ by elimination on $[A \\ I]$. Extend to a $5 \\times 5$ \u201calternating matrix\u201d and guess its inverse:\n    \\[\n    A = \\begin{bmatrix} 1 & -1 & 1 & -1 \\\\ 0 & 1 & -1 & 1 \\\\ 0 & 0 & 1 & -1 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}.\n    \\]",
            "equations": [
                "A^{-1}",
                "[A \\ I]",
                "5 \\times 5"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Compute the products \\(AB\\), \\(BA\\), and \\(A^2\\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "True or false, with reason if true or counterexample if false:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Describe the rows of $ EA $ and the columns of $ AE $ if\n    $$E = \\begin{bmatrix}         1 & 7 \\\\         0 & 1     \\end{bmatrix}.$$",
            "equations": [
                " EA ",
                " AE ",
                "",
                ""
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If rows 1 and 3 of $ B $ are the same, so are rows 1 and 3 of $ AB $.",
            "equations": [
                " B ",
                " AB "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "There are 12 \u201ceven\u201d permutations of \\( (1,2,3,4) \\), with an even number of exchanges. Two of them are \\( (1,2,3,4) \\) with no exchanges and \\( (4,3,2,1) \\) with two exchanges. List the other ten. Instead of writing each 4 by 4 matrix, use the numbers 4, 3, 2, 1 to give the position of the 1 in each row.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Choose a right-hand side which gives no solution and another right-hand side which gives infinitely many solutions. What are two of those solutions?\n    \\begin{align*}\n    3x + 2y &= 10 \\\\\n    6x + 4y &= \\_\\_\\_\\_\\_.\n    \\end{align*}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Compute $H^{-1}$ in two ways for the $3 \\times 3$ Hilbert matrix:\n    \\begin{equation*}\n        H = \\begin{bmatrix}\n            1 & \\frac{1}{2} & \\frac{1}{3} \\\\\n            \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{4} \\\\\n            \\frac{1}{3} & \\frac{1}{4} & \\frac{1}{5}\n        \\end{bmatrix}\n    \\end{equation*}\n    First, compute the exact inverse. Second, round off each number to three significant figures and compute again. Discuss the impact of rounding errors on the results.",
            "equations": [
                "H^{-1}",
                "3 \\times 3"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If $A = A^T$ needs a row exchange, then it also needs a column exchange to stay symmetric. In matrix language, $PA$ loses the symmetry of $A$ but recovers the symmetry.",
            "equations": [
                "A = A^T",
                "PA",
                "A"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If \\( A \\) is invertible and \\( AB = AC \\), prove quickly that \\( B = C \\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Multiply these matrices in the orders \\(EF\\) and \\(FE\\) and \\(E^2\\):\n    \\[\n    E = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    a & 1 & 0 \\\\\n    b & 0 & 1\n    \\end{bmatrix}, \\quad\n    F = \\begin{bmatrix} \n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & c & 1\n    \\end{bmatrix}\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If \\( A \\) and \\( B \\) have nonzeros in the positions marked by \\( x \\), which zeros are still zero in their factors \\( L \\) and \\( U \\)?\n    \\[\n    A = \\begin{bmatrix}\n    x & x & x & x \\\\\n    x & x & x & 0 \\\\\n    0 & x & x & x \\\\\n    0 & 0 & x & x\n    \\end{bmatrix},\n    \\quad\n    B = \\begin{bmatrix}\n    x & x & x & 0 \\\\\n    x & x & 0 & x \\\\\n    x & 0 & x & x \\\\\n    0 & x & x & x\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Solve by elimination and back-substitution:\n    \\[\n    u + w = 4 \\quad\n    u + v = 3 \\quad\n    u + v + w = 6\n    \\]\n    and\n    \\[\n    v + w = 0 \\quad\n    u + w = 0 \\quad\n    u + v = 6.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If every column of $A$ is a multiple of $(1,1,1)$, then $Ax$ is always a multiple of $(1,1,1)$. Do a $3 \\times 3$ example. How many pivots are produced by elimination?",
            "equations": [
                "A",
                "(1,1,1)",
                "Ax",
                "(1,1,1)",
                "3 \\times 3"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$ CD = -DC $, not allowing the case $ CD = 0 $.",
            "equations": [
                " CD = -DC ",
                " CD = 0 "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If the product $M = ABC$ of three square matrices is invertible, then $A, B, C$ are invertible. Find a formula for $B^{-1}$ that involves $M^{-1}$ and $A$ and $C$.",
            "equations": [
                "M = ABC",
                "A, B, C",
                "B^{-1}",
                "M^{-1}",
                "A",
                "C"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Solve \\( Lc = b \\) to find \\( c \\). Then solve \\( Ux = c \\) to find \\( x \\). What was \\( A \\)?\n    \\[\n    L = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    1 & 1 & 0 \\\\\n    1 & 1 & 1\n    \\end{bmatrix},\n    \\quad\n    U = \\begin{bmatrix}\n    1 & 1 & 1 \\\\\n    0 & 1 & 1 \\\\\n    0 & 0 & 1\n    \\end{bmatrix},\n    \\quad\n    b = \\begin{bmatrix}\n    4 \\\\\n    5 \\\\\n    6\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If the third equation starts with a zero coefficient (it begins with $ 0u $), then no multiple of equation 1 will be subtracted from equation 3.",
            "equations": [
                " 0u "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "\\( A \\) is tridiagonal.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If rows 1 and 3 of $ A $ are the same, so are rows 1 and 3 of $ AB $.",
            "equations": [
                " A ",
                " AB "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If \\( A = LDU \\), with 1s on the diagonals of \\( L \\) and \\( U \\), what is the corresponding factorization of \\( A^T \\)? Note that \\( A \\) and \\( A^T \\) (square matrices with no row exchanges) share the same pivots.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "the first pivot.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "In Problem 22, applying $E_{21}$ and then $E_{32}$ to the column $b = (1,0,0)$ gives $E_{32}E_{21}b =$ . Applying $E_{32}$ before $E_{21}$ gives $E_{21}E_{32}b =$ . When $E_{32}$ comes first, row \\_\\_\\_ feels no effect from row \\_\\_\\_.",
            "equations": [
                "E_{21}",
                "E_{32}",
                "b = (1,0,0)",
                "E_{32}E_{21}b =",
                "E_{32}",
                "E_{21}",
                "E_{21}E_{32}b =",
                "E_{32}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "There are sixteen 2 by 2 matrices whose entries are 1s and 0s. How many are invertible?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Illustrate both formulas when \\(A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 1 \\end{bmatrix}\\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Which number $b$ leads later to a row exchange? Which $b$ leads to a missing pivot? In that singular case, find a nonzero solution $x$, $y$, $z$.\n    \\begin{align*}\n    x + by &= 0 \\\\\n    x - 2y - z &= 0 \\\\\n    y + z &= 0.\n    \\end{align*}",
            "equations": [
                "b",
                "b",
                "x",
                "y",
                "z"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "The product of two lower triangular matrices is again lower triangular (all its entries above the main diagonal are zero). Confirm this with a $ 3 \\times 3 $ example, and then explain how it follows from the laws of matrix multiplication.",
            "equations": [
                " 3 \\times 3 "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If all diagonal entries of \\( A \\) are zero, then \\( A \\) is singular.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Given the block matrices \\( A = \\begin{bmatrix} A_1 & A_2 \\\\ A_3 & A_4 \\end{bmatrix} \\) and \\( B = \\begin{bmatrix} B_1 & B_2 \\\\ B_3 & B_4 \\end{bmatrix} \\), where each \\( A_i \\) and \\( B_i \\) are \\( 2 \\times 2 \\) matrices, compute the product \\( AB \\) using block matrix multiplication.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "A group of matrices includes $AB$ and $A^{-1}$ if it includes $A$ and $B$. \u201cProducts and inverses stay in the group.\u201d\n    \\begin{itemize}",
            "equations": [
                "AB",
                "A^{-1}",
                "A",
                "B"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Why are rows of $U$ subtracted off and not rows of $A$?",
            "equations": [
                "U",
                "A"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Find the pivots and the solution for these four equations:\n    \\begin{align*}\n    2x + y &= 0 \\\\\n    x + 2y + z &= 0 \\\\\n    y + 2z + t &= 0 \\\\\n    z + 2t &= 5.\n    \\end{align*}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "What $5 \\times 5$ system replaces (6) if the boundary conditions are changed to $u(0) = 1, u(1) = 0$?",
            "equations": [
                "5 \\times 5",
                "u(0) = 1, u(1) = 0"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$ABD$",
            "equations": [
                "ABD"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "What \\( 2 \\times 2 \\) matrix \\( P_1 \\) projects the vector \\( (x,y) \\) onto the x-axis to produce \\( (x,0) \\)? What matrix \\( P_2 \\) projects onto the y-axis to produce \\( (0,y) \\)? \n    \n    \\textit{If you multiply \\((5,7)\\) by \\( P_1 \\) and then multiply by \\( P_2 \\), you get \\(( )\\) and \\(( )\\).}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "How many exchanges will permute \\( (5,4,3,2,1) \\) back to \\( (1,2,3,4,5) \\)? How many exchanges to change \\( (6,5,4,3,2,1) \\) to \\( (1,2,3,4,5,6) \\)? One is even and the other is odd. For \\( (n, \\ldots, 1) \\) to \\( (1, \\ldots, n) \\), show that \\( n = 100 \\) and 101 are even, \\( n = 102 \\) and 103 are odd.",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If the three solutions in Question 51 are:\n    \\begin{align*}\n        x_1 &= (1,1,1), & x_2 &= (0,1,1), & x_3 &= (0,0,1),\n    \\end{align*}\n    solve $Ax = b$ when $b = (3,5,8)$. \\textbf{Challenge problem}: What is $A$?",
            "equations": [
                "Ax = b",
                "b = (3,5,8)",
                "A"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Rows of $A$ times columns of $B$.",
            "equations": [
                "A",
                "B"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Which right-hand sides $(b_1, b_2, b_3)$ might allow a solution to $Ax = b$?",
            "equations": [
                "(b_1, b_2, b_3)",
                "Ax = b"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Solve by elimination, or show that there is no solution:\n    \\[\n    u + v + w = 0 \\\\\n    u + 2v + 3w = 0 \\\\\n    3u + 5v + 7w = 1\n    \\]\n    and\n    \\[\n    u + v + w = 0 \\\\\n    u + u + 3w = 0 \\\\\n    3u + 5v + 7w = 1.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Use \\texttt{inv(S)} to invert MATLAB\u2019s $4 \\times 4$ symmetric matrix $S = \\texttt{pascal(4)}$. Create Pascal\u2019s lower triangular matrix $A = \\texttt{abs(pascal(4,1))}$ and test $\\texttt{inv(S) = inv(A') * inv(A)}$.",
            "equations": [
                "4 \\times 4",
                "S = \\texttt{pascal(4)}",
                "A = \\texttt{abs(pascal(4,1))}",
                "\\texttt{inv(S) = inv(A') * inv(A)}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "This is the row $x^T A =$ times the column $y = (0,1,0)$.",
            "equations": [
                "x^T A =",
                "y = (0,1,0)"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "\\((x, y) = (2, 5)\\) and \\((3, 7)\\) lie on the line \\(y = mx + c\\). Find \\(m\\) and \\(c\\).",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Will $B^{-1}$ be northwest or southeast?",
            "equations": [
                "B^{-1}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If $(a,b)$ is a multiple of $(c,d)$ with $abcd \\neq 0$, show that $(a,c)$ is a multiple of $(b,d)$. This is surprisingly important: call it a challenge question. You could use numbers first to see how $a$, $b$, $c$, and $d$ are related. The question will lead to: If \n    $$A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$$\n    has dependent rows then it has dependent columns.",
            "equations": [
                "(a,b)",
                "(c,d)",
                "abcd \\neq 0",
                "(a,c)",
                "(b,d)",
                "a",
                "b",
                "c",
                "d",
                "",
                ""
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Draw the cuts in $A$ and $B$ and $AB$ to show how each of the four multiplication rules is really a block multiplication to find $AB$:\n    \\begin{enumerate}",
            "equations": [
                "A",
                "B",
                "AB",
                "AB"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "If \\(A\\) is invertible, what is the inverse of \\(A^T\\)?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "(Very optional) Normally the multiplication of two complex numbers\n    $$(a+ib)(c+id) = (ac\u2212bd) +i(bc+ad)$$\n    involves the four separate multiplications $ ac, bd, bc, $ and $ ad $. Ignoring $ i $, can you compute $ ac\u2212bd $ and $ bc+ad $ with only three multiplications? (You may do additions, such as forming $ a+b $ before multiplying, without any penalty.)",
            "equations": [
                "",
                "",
                " ac, bd, bc, ",
                " ad ",
                " i ",
                " ac\u2212bd ",
                " bc+ad ",
                " a+b "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Find examples of 2 by 2 matrices with \\(a_{12} = \\frac{1}{2}\\) for which:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Suppose $A$ is an $n \\times n$ matrix with rational entries, and the Gauss-Jordan elimination process involves only rational row operations. Prove that if $A$ is invertible, then $A^{-1}$ has only rational entries. How does this result relate to field properties?",
            "equations": [
                "A",
                "n \\times n",
                "A",
                "A^{-1}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "By trial and error find examples of $ 2 \\times 2 $ matrices such that:\n    \\begin{enumerate}",
            "equations": [
                " 2 \\times 2 "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Construct a $3 \\times 3$ example that has 9 different coefficients on the left-hand side, but rows 2 and 3 become zero in elimination. How many solutions to your system with $b = (1,10,100)$ and how many with $b = (0,0,0)$?",
            "equations": [
                "3 \\times 3",
                "b = (1,10,100)",
                "b = (0,0,0)"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Find the $PA = LDU$ factorizations (and check them) for\n    \\[\n    A = \\begin{bmatrix} 0 & 1 & 1 \\\\ 1 & 0 & 1 \\\\ 2 & 3 & 4 \\end{bmatrix}\n    \\]\n    and\n    \\[\n    A = \\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 1 & 1 \\end{bmatrix}.\n    \\]",
            "equations": [
                "PA = LDU"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "The matrix \\( P \\) that multiplies \\( (x,y,z) \\) to give \\( (z,x,y) \\) is also a rotation matrix. Find \\( P \\) and \\( P^3 \\). The rotation axis \\( a = (1,1,1) \\) doesn\u2019t move, it equals \\( Pa \\). What is the angle of rotation from \\( v = (2,3,-5) \\) to \\( Pv = (-5,2,3) \\)?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "(For $3 \\times 3$ matrices) Choose the only $B$ such that for every matrix $A$:\n    \\begin{enumerate}",
            "equations": [
                "3 \\times 3",
                "B",
                "A"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Can the matrix be symmetric?",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Which number \\( c \\) leads to zero in the second pivot position? A row exchange is needed and \\( A = LU \\) is not possible. Which \\( c \\) produces zero in the third pivot position? Then a row exchange can't help and elimination fails:\n    \\[\n    A = \\begin{bmatrix}\n    1 & c & 0 \\\\\n    2 & 4 & 1 \\\\\n    3 & 5 & 1\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "What rows or columns or matrices do you multiply to find:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$Ax$ gives the amounts of steel, rubber, and labor to produce $x$ in Problem 62. \n    \\begin{itemize}",
            "equations": [
                "Ax",
                "x"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Write down the 3 by 3 matrices with entries\n        \\[\n        a_{ij} = i - j \\quad \\text{and} \\quad b_{ij} = \\frac{i}{j}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Show that $A = 4 \\cdot I_4 - \\mathbf{1}_{4 \\times 4}$ is not invertible: Multiply $A \\cdot \\mathbf{1}_{4 \\times 1}$.",
            "equations": [
                "A = 4 \\cdot I_4 - \\mathbf{1}_{4 \\times 4}",
                "A \\cdot \\mathbf{1}_{4 \\times 1}"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "$ A(A+B) + B(A+B) $",
            "equations": [
                " A(A+B) + B(A+B) "
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Apply elimination to the system\n    \\begin{align*}\n    u + v + w &= -2 \\\\\n    3u + 3v - w &= 6 \\\\\n    u - v + w &= -1.\n    \\end{align*}\n    When a zero arises in the pivot position, exchange that equation for the one below it and proceed. What coefficient of $v$ in the third equation, in place of the present $-1$, would make it impossible to proceed\u2014and force elimination to break down?",
            "equations": [
                "v",
                "-1"
            ]
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Apply elimination to produce the factors \\( L \\) and \\( U \\) for:\n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 8 & 7 \\end{bmatrix},\n    \\quad A = \\begin{bmatrix} 3 & 1 & 1 \\\\ 1 & 3 & 1 \\\\ 1 & 1 & 3 \\end{bmatrix},\n    \\quad A = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 4 & 4 \\\\ 1 & 4 & 8 \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Matrices and Gaussian Elimination",
            "question_latex": "Starting with a first plane \\(u + 2v - w = 6\\), find the equation for:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Under what condition on the columns of $A$ (which may be rectangular) is $A^TA$ invertible?",
            "equations": [
                "A",
                "A^TA"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If $S$ is the subspace of $\\mathbb{R}^3$ containing only the zero vector, what is $S^\\perp$? If $S$ is spanned by $(1,1,1)$, what is $S^\\perp$? If $S$ is spanned by $(2,0,0)$ and $(0,0,3)$, what is $S^\\perp$?",
            "equations": [
                "S",
                "\\mathbb{R}^3",
                "S^\\perp",
                "S",
                "(1,1,1)",
                "S^\\perp",
                "S",
                "(2,0,0)",
                "(0,0,3)",
                "S^\\perp"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The vector in \\(\\mathbf{V}\\) closest to the vector \\(\\mathbf{b} = (0, 1, 0, -1)\\) in \\(\\mathbf{V}^\\perp\\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Find the best straight-line fit to the following measurements, and sketch your solution:\n    \\[\n    y = 2 \\text{ at } t = -1, \\quad y = 0 \\text{ at } t = 0, \\quad y = -3 \\text{ at } t = 1, \\quad y = -5 \\text{ at } t = 2.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "(a) Write the four equations for fitting \\( y = C + Dt \\) to the data \n    \\[\n    y = -4 \\text{ at } t = -2, \\quad y = -3 \\text{ at } t = -1, \\quad y = -1 \\text{ at } t = 1, \\quad y = 0 \\text{ at } t = 2.\n    \\]\n    Show that the columns are orthogonal.\n    \n    (b) Find the optimal straight line, draw its graph, and write \\( E^2 \\).\n    \n    (c) Interpret the zero error in terms of the original system of four equations in two unknowns: The right-hand side \\( (-4, -3, -1, 0) \\) is in the space.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The columns add up to a column of 0s, the rows add to a row of 1s.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If \\( \\mathbf{u} \\) is a unit vector, show that \\( Q = I - 2 \\mathbf{u} \\mathbf{u}^T \\) is a symmetric orthogonal matrix. (It is a reflection, also known as a Householder transformation.) Compute \\( Q \\) when\n    \\[\n    \\mathbf{u}^T = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} & -\\frac{1}{2} & -\\frac{1}{2} \\end{pmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Compute \\( y = F_8c \\) by the three steps of the Fast Fourier Transform if \\( c = (1,0,1,0,1,0,1,0) \\). Repeat the computation with \\( c = (0,1,0,1,0,1,0,1) \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the classical Gram-Schmidt process and the modified Gram-Schmidt process for constructing an orthonormal basis. Show that both methods produce the same orthonormal basis in exact arithmetic but differ in numerical stability. Provide an example where the classical Gram-Schmidt process fails due to numerical instability.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Show that the best least-squares fit to a set of measurements \\(y_1, \\dots, y_m\\) by a horizontal line (a constant function \\(y = C\\)) is their average\n    \\[\n    C = \\frac{y_1 + \\dots + y_m}{m}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "What multiple of $a_1$ should be subtracted from $a_2$, to make the result orthogonal to $a_1$? Sketch a figure.",
            "equations": [
                "a_1",
                "a_2",
                "a_1"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If \\(\\mathbf{P_C} = \\mathbf{A}(\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\\) is the projection onto the column space of \\(\\mathbf{A}\\), what is the projection \\(\\mathbf{P_R}\\) onto the row space? (It is not \\(\\mathbf{P_C}^T\\)!)",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The Fourier series representation of a function \\( f(x) \\) is given by\n    \\[\n    f(x) = \\frac{a_0}{2} + \\sum_{n=1}^{\\infty} \\left( a_n \\cos(nx) + b_n \\sin(nx) \\right).\n    \\]\n    Using the orthogonality of the Fourier basis functions, derive explicit expressions for the Fourier coefficients \\( a_n \\) and \\( b_n \\). Show that the inner product structure leads to these coefficients being projections of \\( f(x) \\) onto the basis functions.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Factor \n    \\[\n    \\begin{bmatrix}\n        \\cos\\theta & \\sin\\theta \\\\\n        \\sin\\theta & 0\n    \\end{bmatrix}\n    \\]\n    into QR, recognizing that the first column is already a unit vector.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If the columns of $A$ are orthogonal to each other, what can you say about the form of $A^TA$? If the columns are orthonormal, what can you say then?",
            "equations": [
                "A",
                "A^TA"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Define the projection matrix \\( P \\) that projects any vector \\( b \\in \\mathbb{R}^m \\) onto the column space of \\( A \\). Show that \\( P \\) is symmetric and idempotent, i.e., \\( P^2 = P \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Write out \\(E^2 = \\| \\mathbf{A}\\mathbf{x} - \\mathbf{b} \\|^2\\) and set to zero its derivatives with respect to \\(u\\) and \\(v\\), if\n    \\[\n    \\mathbf{A} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}, \\quad \\mathbf{x} = \\begin{bmatrix} u \\\\ v \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 4 \\end{bmatrix}.\n    \\]\n    Compare the resulting equations with \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x}_b = \\mathbf{A}^T \\mathbf{b}\\), confirming that calculus as well as geometry gives the normal equations. Find the solution \\(\\mathbf{x}_b\\) and the projection \\(\\mathbf{p} = \\mathbf{A}\\mathbf{x}_b\\). Why is \\(\\mathbf{p} = \\mathbf{b}\\)?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the space of continuous functions on the interval \\( [0,1] \\) with the inner product defined by \n    \\[\n    \\langle f, g \\rangle = \\int_0^1 f(x) g(x) \\,dx.\n    \\]\n    Use the Gram-Schmidt process to construct an orthonormal basis for the space spanned by the functions \\( \\{1, x, x^2\\} \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The Fourier matrix \\( F_n \\) of order \\( n \\) is given by\n    \\[\n    F_n = \\frac{1}{\\sqrt{n}} \\left[ e^{2\\pi i jk/n} \\right]_{j,k=0}^{n-1}.\n    \\]\n    Show that \\( F_n \\) is unitary, meaning \\( F_n^* F_n = I_n \\), and explain its connection to the discrete Fourier transform (DFT). Prove that the columns of \\( F_n \\) form an orthonormal set with respect to the standard inner product in \\( \\mathbb{C}^n \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "What is the projection $p$ of $b = (1,2,2)$ onto $a = (2,-2,1)$?",
            "equations": [
                "p",
                "b = (1,2,2)",
                "a = (2,-2,1)"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Use Gram-Schmidt to construct an orthonormal pair \\( q_1, q_2 \\) from:\n    \\[\n    a_1 = (4,5,2,2), \\quad a_2 = (1,2,0,0).\n    \\]\n    Express \\( a_1 \\) and \\( a_2 \\) as combinations of \\( q_1 \\) and \\( q_2 \\), and find the triangular \\( R \\) in \\( A = QR \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Which straight line gives the best fit to the following data: $b = 0$ at $t = 0$, $b = 0$ at $t = 1$, $b = 12$ at $t = 3$?",
            "equations": [
                "b = 0",
                "t = 0",
                "b = 0",
                "t = 1",
                "b = 12",
                "t = 3"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Verify that the best line goes through the center point \\((\\mathbf{b_t}, \\mathbf{b_b}) = (2, 9)\\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "What are \\( F_2 \\) and \\( F_4 \\) for the \\( 4 \\times 4 \\) Fourier matrix \\( F \\)?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider an \\( m \\times n \\) matrix \\( A \\) with full column rank. Define the projection matrix \\( P = A(A^T A)^{-1} A^T \\) that projects vectors onto the column space of \\( A \\). Show that for any \\( b \\in \\mathbb{R}^m \\), the vector \\( Pb \\) is the closest vector to \\( b \\) in the column space of \\( A \\). Additionally, prove that the residual \\( (I - P)b \\) is orthogonal to the column space of \\( A \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Put bases for the orthogonal subspaces $V$ and $W$ into the columns of matrices $V$ and $W$. Why does $V^T W = 0$ matrix? This matches $v^T w = 0$ for vectors.",
            "equations": [
                "V",
                "W",
                "V",
                "W",
                "V^T W = 0",
                "v^T w = 0"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Show that these modified Gram-Schmidt steps produce the same \\( C \\) as in equation (10):\n    \\[\n    C^* = c - (q_1^T c) q_1 \\quad \\text{and} \\quad C = C^* - (q_2^T C^*) q_2.\n    \\]\n    This is much more stable, to subtract the projections one at a time.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "With \\(\\mathbf{b} = (0, 8, 8, 20)\\) at \\(t = 0, 1, 3, 4\\), set up and solve the normal equations \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x_b} = \\mathbf{A}^T \\mathbf{b}\\). For the best straight line as in Figure 3.9a, find its four heights \\(\\mathbf{p_i}\\) and four errors \\(\\mathbf{e_i}\\). What is the minimum value \\(E^2 = e_1^2 + e_2^2 + e_3^2 + e_4^2\\)?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the space of square-integrable functions \\( L^2([0, \\pi]) \\) with the inner product \n    \\[\n    \\langle f, g \\rangle = \\int_0^{\\pi} f(x) g(x) \\,dx.\n    \\]\n    Apply the Gram-Schmidt process to the functions \\( \\{1, \\sin x, \\sin 2x\\} \\) to construct an orthonormal basis.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The columns of the Fourier matrix $F$ are the eigenvectors of the cyclic permutation $P$. Multiply $PF$ to find the eigenvalues $\\lambda_0$ to $\\lambda_3$:\n    \\begin{equation*}\n        \\begin{bmatrix}\n            0 & 1 & 0 & 0 \\\\\n            0 & 0 & 1 & 0 \\\\\n            0 & 0 & 0 & 1 \\\\\n            1 & 0 & 0 & 0\n        \\end{bmatrix}\n        \\begin{bmatrix}\n            1 & 1 & 1 & 1 \\\\\n            1 & i & i^2 & i^3 \\\\\n            1 & i^2 & i^4 & i^6 \\\\\n            1 & i^3 & i^6 & i^9\n        \\end{bmatrix}\n        =\n        \\begin{bmatrix}\n            1 & 1 & 1 & 1 \\\\\n            1 & i & i^2 & i^3 \\\\\n            1 & i^2 & i^4 & i^6 \\\\\n            1 & i^3 & i^6 & i^9\n        \\end{bmatrix}\n        \\begin{bmatrix}\n            \\lambda_0 \\\\\n            \\lambda_1 \\\\\n            \\lambda_2 \\\\\n            \\lambda_3\n        \\end{bmatrix}.\n    \\end{equation*}\n    This is $PF = F\\Lambda$ or $P = F\\Lambda F^{-1}$.",
            "equations": [
                "F",
                "P",
                "PF",
                "\\lambda_0",
                "\\lambda_3",
                "PF = F\\Lambda",
                "P = F\\Lambda F^{-1}"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Column space contains $\\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\end{bmatrix}$ and $\\begin{bmatrix} 2 \\\\ -3 \\\\ 5 \\end{bmatrix}$, nullspace contains $\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$.",
            "equations": [
                "\\begin{bmatrix} 1 \\\\ 2 \\\\ -3 \\end{bmatrix}",
                "\\begin{bmatrix} 2 \\\\ -3 \\\\ 5 \\end{bmatrix}",
                "\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Continuing Problems 21\u201322, find the projection matrix \\(P_3\\) onto \\(\\mathbf{a_3} = (2, -1, 2)\\). Verify that \\(P_1 + P_2 + P_3 = I\\). The basis \\(\\mathbf{a_1}, \\mathbf{a_2}, \\mathbf{a_3}\\) is orthogonal!",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "(a) If \\(\\mathbf{P} = \\mathbf{P}^T\\), show that \\(\\mathbf{P}\\) is a projection matrix.\n    (b) What subspace does the matrix \\(\\mathbf{P} = 0\\) project onto?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Prove that if \\( v_1, \\dots, v_n \\) is an orthonormal basis for \\( \\mathbb{R}^n \\), then:\n    \\[\n    v_1 v_1^T + \\dots + v_n v_n^T = I.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the modified Gram-Schmidt algorithm as a variation of the classical Gram-Schmidt process for computing the QR decomposition. Show that the modified Gram-Schmidt process produces the same result as the classical approach but with improved numerical stability.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the problem of fitting a straight line to a given dataset using orthogonal projections. Let \\( A \\) be the matrix whose columns are the basis vectors \\( [1, x] \\) for the space of linear functions, and let \\( b \\) be the vector of observed values. Show that the least squares solution corresponds to the orthogonal projection of \\( b \\) onto the column space of \\( A \\). Determine the conditions under which the solution is unique.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Let $P$ be the plane in $\\mathbb{R}^3$ with equation $x + 2y - z = 0$. Find a vector perpendicular to $P$. What matrix has the plane $P$ as its null space, and what matrix has $P$ as its row space?",
            "equations": [
                "P",
                "\\mathbb{R}^3",
                "x + 2y - z = 0",
                "P",
                "P",
                "P"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Suppose $L$ is a one-dimensional subspace (a line) in $\\mathbb{R}^3$. Its orthogonal complement $L^\\perp$ is the perpendicular to $L$. Then $(L^\\perp)^\\perp$ is a perpendicular to $L^\\perp$. In fact, $(L^\\perp)^\\perp$ is the same as $\\cdots$.",
            "equations": [
                "L",
                "\\mathbb{R}^3",
                "L^\\perp",
                "L",
                "(L^\\perp)^\\perp",
                "L^\\perp",
                "(L^\\perp)^\\perp",
                "\\cdots"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider an ill-conditioned matrix \\( A \\). Prove that the QR factorization provides a numerically stable method for computing the solution to the least squares problem compared to normal equations. Provide an explicit example where the use of QR factorization significantly improves numerical accuracy over the direct normal equation approach.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Find the fourth Legendre polynomial. It is a cubic \\( x^3 + ax^2 + bx + c \\) that is orthogonal to 1, \\( x \\), and \\( x^2 - \\frac{1}{3} \\) over the interval \\( -1 \\leq x \\leq 1 \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Let $S$ be a subspace of $\\mathbb{R}^n$. Explain what $(S^\\perp)^\\perp = S$ means and why it is true.",
            "equations": [
                "S",
                "\\mathbb{R}^n",
                "(S^\\perp)^\\perp = S"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider an iterative refinement approach to solving the weighted least squares problem, where the weights are updated dynamically based on residual errors. Formulate an iterative algorithm that adjusts the weights as \\( W_{k+1} = \\text{diag}(|r_k|^{-1}) \\), where \\( r_k \\) is the residual at step \\( k \\). Analyze the convergence of this approach and its relationship to robust regression methods.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If the vectors \\( q_1, q_2, q_3 \\) are orthonormal, what combination of \\( q_1 \\) and \\( q_2 \\) is closest to \\( q_3 \\)?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Prove that in a Hilbert space \\( H \\), the Gram-Schmidt process applied to a linearly independent sequence produces an orthonormal sequence that spans the same subspace. Use this result to construct an explicit orthonormal basis for the space of polynomials up to degree \\( n \\) in \\( L^2([-1,1]) \\) using the Gram-Schmidt process.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Two subspaces that meet only in the zero vector are orthogonal.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Suppose $A$ is a symmetric matrix ($A^T = A$).\n    \\begin{enumerate}",
            "equations": [
                "A",
                "A^T = A"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "(a) Suppose you guess your professor\u2019s age, making errors \\( e = -2, -1, 5 \\) with probabilities \\( \\frac{1}{2}, \\frac{1}{4}, \\frac{1}{4} \\). Check that the expected error \\( E(e) \\) is zero and find the variance \\( E(e^2) \\).\n    \n    (b) If the professor guesses too (or tries to remember), making errors \\( -1, 0, 1 \\) with probabilities \\( \\frac{1}{8}, \\frac{6}{8}, \\frac{1}{8} \\), what weights \\( w_1 \\) and \\( w_2 \\) give the reliability of your guess and the professor\u2019s guess?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Suppose \\(\\mathbf{P}\\) is the projection matrix onto the subspace \\(\\mathbf{S}\\) and \\(\\mathbf{Q}\\) is the projection onto the orthogonal complement \\(\\mathbf{S}^\\perp\\). What are \\(\\mathbf{P} + \\mathbf{Q}\\) and \\(\\mathbf{P}\\mathbf{Q}\\)? Show that \\(\\mathbf{P} - \\mathbf{Q}\\) is its own inverse.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If \\( y = (1,1,1,1) \\), show that \\( c = (1,0,0,0) \\) satisfies \\( F_4c = y \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Solve the \\( 4 \\times 4 \\) system if the right-hand sides are \\( y_0 = 2, y_1 = 0, y_2 = 2, y_3 = 0 \\). In other words, solve \\( F_4c = y \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If \\(\\mathbf{P}\\) is the projection onto the column space of \\(\\mathbf{A}\\), what is the projection onto the left nullspace?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "For the closest parabola \\(\\mathbf{b} = C + Dt + Et^2\\) to the same four points, write the unsolvable equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) in three unknowns \\(\\mathbf{x} = (C, D, E)\\). Set up the three normal equations \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{x_b} = \\mathbf{A}^T \\mathbf{b}\\) (solution not required). You are now fitting a parabola to four points\u2014what is happening in Figure 3.9b?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Find the matrix that projects every point in the plane onto the line \\(x + 2y = 0\\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Suppose that \\( H \\) is an infinite-dimensional Hilbert space. Show that every sequence \\( \\{x_n\\} \\) in \\( H \\) has a weakly convergent subsequence, i.e., there exists \\( x \\in H \\) such that\n    \\[\n    \\langle x_n, y \\rangle \\to \\langle x, y \\rangle\n    \\]\n    for all \\( y \\in H \\). Provide an example where strong convergence fails but weak convergence holds.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "To solve a rectangular system $Ax = b$, we replace $A^{-1}$ (which doesn\u2019t exist) by $(A^TA)^{-1}A^T$ (which exists if $A$ has independent columns). Show that this is a left-inverse of $A$ but not a right-inverse. On the left of $A$ it gives the identity; on the right it gives the projection $P$.",
            "equations": [
                "Ax = b",
                "A^{-1}",
                "(A^TA)^{-1}A^T",
                "A",
                "A",
                "A",
                "P"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider a matrix \\( A \\) whose columns form an orthonormal basis for \\( \\mathbb{R}^m \\). Show that the least squares solution simplifies to \\( x = A^T b \\) and compare it to the general case where \\( A \\) is not orthonormal.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Prove that if \\( H \\) is a Hilbert space, then every bounded linear functional \\( f: H \\to \\mathbb{R} \\) (or \\( \\mathbb{C} \\)) can be represented as an inner product with a fixed element of \\( H \\), i.e., there exists a unique \\( g \\in H \\) such that\n    \\[\n    f(v) = \\langle v, g \\rangle \\quad \\forall v \\in H.\n    \\]\n    This is known as the Riesz Representation Theorem. Provide a constructive proof of this result.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Define the notion of an orthogonal projection onto a closed subspace \\( V \\) of a Hilbert space \\( H \\). Show that for any vector \\( x \\in H \\), there exists a unique vector \\( v \\in V \\) such that \\( x - v \\) is orthogonal to \\( V \\). Prove that this projection is a linear operator and is idempotent.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Given the weighting matrix:\n    \\[\n    W =\n    \\begin{bmatrix}\n    2 & 1 \\\\\n    1 & 0\n    \\end{bmatrix}\n    \\]\n    find the \\( W \\)-inner product of \\( (1,0) \\) with \\( (0,1) \\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "All entries in the factorization of \\( F_6 \\) involve powers of \\( \\omega \\), the sixth root of 1:\n    \\[\n    F_6 =\n    \\begin{bmatrix}\n        I & D \\\\\n        I & -D\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        F_3 & 0 \\\\\n        0 & F_3\n    \\end{bmatrix}\n    P.\n    \\]\n    Write these factors with \\( 1, \\omega, \\omega^2 \\) in \\( D \\) and \\( 1, \\omega^2, \\omega^4 \\) in \\( F_3 \\). Multiply!",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The QR decomposition can be used to solve the least squares problem \\( Ax = b \\) for an overdetermined system \\( A \\in \\mathbb{R}^{m \\times n} \\) with \\( m > n \\). Show that using QR factorization, the normal equation solution can be rewritten as \\( Rx = Q^Tb \\). Prove that this formulation avoids issues related to ill-conditioning that arise in normal equations.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Let \\( A \\) be a symmetric positive definite matrix. Show that the QR factorization of \\( A \\) can be used in iterative methods such as the conjugate gradient method to solve the linear system \\( Ax = b \\). Explain how QR factorization improves numerical stability in such iterative methods.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Suppose \\(L_1\\) is the line through the origin in the direction of \\(\\mathbf{a_1}\\) and \\(L_2\\) is the line through \\(\\mathbf{b}\\) in the direction of \\(\\mathbf{a_2}\\). To find the closest points \\(\\mathbf{x_1a_1}\\) and \\(\\mathbf{b} + \\mathbf{x_2a_2}\\) on the two lines, write the two equations for \\(\\mathbf{x_1}\\) and \\(\\mathbf{x_2}\\) that minimize \\(\\|\\mathbf{x_1a_1} - \\mathbf{x_2a_2} - \\mathbf{b}\\|\\). Solve for \\(\\mathbf{x}\\) if \\(\\mathbf{a_1} = (1, 1, 0)\\), \\(\\mathbf{a_2} = (0, 1, 0)\\), and \\(\\mathbf{b} = (2, 1, 4)\\).",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Consider the space of square-integrable functions on the interval \\( [-\\pi, \\pi] \\), denoted as \\( L^2([-\\pi, \\pi]) \\). The Fourier basis consists of the functions \\( \\{1, \\cos(nx), \\sin(nx) \\}_{n=1}^{\\infty} \\). Prove that this set forms an orthogonal basis under the inner product \n    \\[\n    \\langle f, g \\rangle = \\int_{-\\pi}^{\\pi} f(x) g(x) \\,dx.\n    \\]\n    Then, derive the explicit Fourier series expansion of an arbitrary function \\( f(x) \\in L^2([-\\pi, \\pi]) \\) in terms of these basis functions.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If the vectors \\(\\mathbf{a_1}\\), \\(\\mathbf{a_2}\\), and \\(\\mathbf{b}\\) are orthogonal, what are \\(\\mathbf{A}^T \\mathbf{A}\\) and \\(\\mathbf{A}^T \\mathbf{b}\\)? What is the projection of \\(\\mathbf{b}\\) onto the plane of \\(\\mathbf{a_1}\\) and \\(\\mathbf{a_2}\\)?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Show that the determinant of the projection matrix \\( P = A (A^T A)^{-1} A^T \\) is zero when \\( A \\) is not square. Explain why this must be the case.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The Schwarz inequality has a one-line proof if \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) are normalized ahead of time to be unit vectors:\n    \\[\n    |\\mathbf{a}^T \\mathbf{b}| = \\left| \\sum a_j b_j \\right| \\leq \\sum |a_j| |b_j| \\leq \\sum |a_j|^2 + |b_j|^2 = \\frac{1}{2} + \\frac{1}{2} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\|.\n    \\]\n    Which previous problem justifies the middle step?",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "This is a system of equations $Ax = b$ with no solution:\n    \\begin{align*}\n        x + 2y + 2z &= 5 \\\\\n        2x + 2y + 3z &= 5 \\\\\n        3x + 4y + 5z &= 9.\n    \\end{align*}\n    Find numbers $y_1, y_2, y_3$ to multiply the equations so they add to $0 = 1$. You have found a vector $y$ in which subspace? The inner product $y^T b$ is 1.",
            "equations": [
                "Ax = b",
                "y_1, y_2, y_3",
                "0 = 1",
                "y",
                "y^T b"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "The Fourier series expansion of a function \\( f(x) \\) on \\( [-\\pi, \\pi] \\) is known to converge in the \\( L^2 \\)-norm due to the completeness of the trigonometric basis. Prove that the sequence of partial sums of the Fourier series forms a best approximation to \\( f(x) \\) in the sense of the \\( L^2 \\)-norm, i.e., it minimizes the error \n    \\[\n    \\int_{-\\pi}^{\\pi} \\left| f(x) - S_n(x) \\right|^2 dx,\n    \\]\n    where \\( S_n(x) \\) is the \\( n \\)th partial sum of the Fourier series. Use the concept of orthogonal projections in Hilbert spaces to justify this result.",
            "equations": []
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "Find the cosine of the angle between the vectors $(3,4)$ and $(4,3)$.",
            "equations": [
                "(3,4)",
                "(4,3)"
            ]
        },
        {
            "chapter": "Orthogonality",
            "question_latex": "If $Ax$ is in the nullspace of $A^T$ then $Ax = 0$. Reason: $Ax$ is also in the of $A$ and the spaces are . Conclusion: $A^T A$ has the same nullspace as $A$.",
            "equations": [
                "Ax",
                "A^T",
                "Ax = 0",
                "Ax",
                "A",
                "A^T A",
                "A"
            ]
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Find the SVD from the eigenvectors \\( v_1, v_2 \\) of \\( A^T A \\) and \\( A v_i = \\sigma_i u_i \\):}\n    \\[\n    \\text{Fibonacci matrix } A = \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 0\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "For a 1D finite element problem, derive the stiffness matrix for a triangular element. Discuss how this element is used to discretize a domain and solve a boundary value problem.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Which of \\( A_1, A_2, A_3, A_4 \\) has two positive eigenvalues? Test \\( a > 0 \\) and \\( ac > b^2 \\), don\u2019t compute the eigenvalues. Find an \\( x \\) so that \\( x^T A_1 x < 0 \\).\n    \\[\n    A_1 = \\begin{bmatrix} 5 & 6 \\\\ 6 & 7 \\end{bmatrix}, \n    A_2 = \\begin{bmatrix} -1 & -2 \\\\ -2 & -5 \\end{bmatrix}, \n    A_3 = \\begin{bmatrix} 1 & 10 \\\\ 10 & 100 \\end{bmatrix}, \n    A_4 = \\begin{bmatrix} 1 & 10 \\\\ 10 & 101 \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{For the hat functions \\( V_1 \\) and \\( V_2 \\) centered at \\( x = h = \\frac{1}{3} \\) and \\( x = 2h = \\frac{2}{3} \\), compute the 2 by 2 mass matrix \\( M_{ij} = \\int V_i V_j \\, dx \\), and solve the eigenvalue problem \\( A x = \\lambda M x \\).}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Define the finite element method and explain its significance in solving partial differential equations (PDEs). Provide a detailed discussion on how the finite element method discretizes the domain and how it translates a continuous problem into a solvable system of algebraic equations.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "What is the L\u00f6wner-Heinz inequality, and how is it applied in matrix analysis? Provide a detailed explanation of its geometric interpretation and discuss its importance in the context of matrix functions, particularly when applied to positive semidefinite matrices. Prove the L\u00f6wner-Heinz inequality for the matrices \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "For a 1D bar with constant cross-sectional area subjected to an axial force, derive the stiffness matrix and solve for the displacement at each node using finite element analysis.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given a matrix \\( A \\), define and explain the relationship between the rank of \\( A \\) and its singular values. Prove that the rank of \\( A \\) is equal to the number of non-zero singular values.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{If \\( A \\) and \\( B \\) are positive definite, then \\( A + B \\) is positive definite. Pivots and eigenvalues are not convenient for \\( A + B \\). Much better to prove \\( x^T (A + B) x > 0 \\).}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Discuss the connection between the minimum principle and the method of steepest descent in optimization. Provide an example illustrating how the gradient of a function leads to the minimum principle.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Verify if the matrix \n    \\[\n    A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n    \\]\n    is positive definite by using Sylvester\u2019s criterion.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Show that the smallest eigenvalue \\( \\lambda_1 \\) of \\( A x = \\lambda M x \\) is not larger than the ratio \\( \\frac{a_{11}}{m_{11}} \\) of the corner entries.}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the function \\( f(x, y) = x^2 + y^2 - 6xy \\), find the critical points and classify them using the second-derivative test.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{If \\( A \\) is positive definite and \\( a_{11} \\) is increased, prove from cofactors that the determinant is increased. Show by example that this can fail if \\( A \\) is indefinite.}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "For a 1D linear finite element with two nodes, derive the global stiffness matrix for a structure subjected to a uniform distributed load. Assume that the element has Young's modulus \\( E = 210 \\, \\text{GPa} \\) and the element length \\( L = 2 \\, \\text{m} \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{If you throw away two rows and columns of \\( A \\), what inequalities do you expect between the smallest eigenvalue \\( \\mu \\) of the new matrix and the original \\( \\lambda \\)'s?}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Explain the process of solving the system of equations resulting from the finite element method. How does the assembly of the global stiffness matrix and force vector work, and what methods are used to solve the resulting linear system?",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{For \\( F_1(x,y) = \\frac{1}{4}x^4 + x^2y + y^2 \\) and \\( F_2(x,y) = x^3 + xy - x \\), find the second derivative matrices \\( A_1 \\) and \\( A_2 \\):}\n    \\[\n    A = \\begin{bmatrix}\n    \\frac{\\partial^2 F}{\\partial x^2} & \\frac{\\partial^2 F}{\\partial x \\partial y} \\\\\n    \\frac{\\partial^2 F}{\\partial y \\partial x} & \\frac{\\partial^2 F}{\\partial y^2}\n    \\end{bmatrix}\n    \\]\n    \\( A_1 \\) is positive definite, so \\( F_1 \\) is concave up (convex). Find the minimum point of \\( F_1 \\) and the saddle point of \\( F_2 \\) (look where first derivatives are zero).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Consider the matrix \n    \\[\n    A = \\begin{bmatrix} 4 & 2 & 1 \\\\ 2 & 3 & 1 \\\\ 1 & 1 & 2 \\end{bmatrix}.\n    \\]\n    Determine if it is positive definite by calculating the eigenvalues and principal minors.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the weak form of the boundary value problem for the wave equation:\n    \\[\n    \\frac{\\partial^2 u}{\\partial t^2} - c^2 \\Delta u = 0, \\quad u = 0 \\text{ on } \\partial\\Omega.\n    \\]\n    Show how the weak formulation leads to a system of equations for the finite element method.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "The only positive definite projection matrix is \\( P = I \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the element stiffness matrix for a 2D rectangular finite element. Assume the element has uniform material properties and discuss how the stiffness matrix is derived using shape functions.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Discuss the significance of the spectral properties of positive semidefinite matrices in optimization. How can eigenvalues and eigenvectors be used to analyze the stability and optimality of solutions to optimization problems involving positive semidefinite matrices? Given \\( A = \\begin{pmatrix} 6 & 2 \\\\ 2 & 6 \\end{pmatrix} \\), find the eigenvalues and eigenvectors, and interpret them in the context of optimization.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{If the symmetric matrices \\( A \\) and \\( M \\) are indefinite, \\( A x = \\lambda M x \\) might not have real eigenvalues. Construct a 2 by 2 example.}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Find the critical points of the function \\( f(x, y) = 4x^2 + 4y^2 - 16x - 8y + 18 \\). Classify them as minima, maxima, or saddle points using the second-derivative test.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the matrix \n    \\[\n    A = \\begin{bmatrix} 7 & 3 & 4 \\\\ 3 & 7 & 5 \\\\ 4 & 5 & 7 \\end{bmatrix}\n    \\]\n    determine if it is positive definite by checking the eigenvalues and principal minors.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the finite element formulation for a 1D elasticity problem. Assume the material is isotropic, and the structure is subjected to a uniform tensile force.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Prove that a function \\( f(x) \\) that satisfies the minimum principle must have a positive definite Hessian matrix. Use the second-order necessary condition for optimality to demonstrate this property, and provide an example where this condition is verified.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{For} \n    \\[\n    C = \\begin{bmatrix}\n    2 & 0 \\\\\n    0 & -1\n    \\end{bmatrix} \\quad \\text{and} \\quad A = \\begin{bmatrix}\n    1 & 1 \\\\\n    1 & 1\n    \\end{bmatrix},\n    \\]\n    confirm that \\( C^T A C \\) has eigenvalues of the same signs as \\( A \\). Construct a chain of nonsingular matrices \\( C(t) \\) linking \\( C \\) to an orthogonal matrix \\( Q \\). Why is it impossible to construct a nonsingular chain linking \\( C \\) to the identity matrix?",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Find the eigenvalues of the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}\n    \\]\n    and determine if the matrix is positive definite.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the minimum principle for a functional involving higher-order derivatives, such as \\( J(y) = \\int_0^1 \\left( y^{(3)}(x)^2 + y(x)^2 \\right) dx \\). Solve for the function \\( y(x) \\) that minimizes this functional.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Find the eigenvalues and eigenvectors of} \n    \\[\n    A x = \\lambda M x:\n    \\quad A = \\begin{bmatrix} \n    6 & -3 \\\\\n    -3 & 6\n    \\end{bmatrix}, \\quad M = \\begin{bmatrix}\n    4 & 1 \\\\\n    1 & 4\n    \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Explain the application of Ky Fan's inequalities in the context of low-rank approximation problems. How can these inequalities be used to derive bounds on the rank of matrix approximations and to solve optimization problems involving low-rank matrices? Given a matrix \\( A = \\begin{pmatrix} 6 & 2 \\\\ 2 & 3 \\end{pmatrix} \\), use Ky Fan\u2019s inequalities to find the rank of a low-rank approximation.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Explain the importance of the singular values in dimensionality reduction. How do they contribute to reducing the rank and improving computational efficiency in applications such as principal component analysis (PCA)?",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "In a 2D finite element problem, derive the stiffness matrix for a triangular element using linear interpolation. Assume the element has nodes at \\( (x_1, y_1), (x_2, y_2), (x_3, y_3) \\), and derive the matrix form of the element's stiffness matrix.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the matrix \\( A = \\begin{pmatrix} 2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\), determine whether it is positive semidefinite. If so, explain why this matrix is useful in a machine learning application such as kernel methods for regression or classification.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Solve a simple finite element problem involving the solution of a 1D Poisson equation:\n    \\[\n    -\\frac{d^2u}{dx^2} = f(x), \\quad u(0) = 0, \\quad u(1) = 0.\n    \\]\n    Use linear finite elements to discretize the problem and assemble the stiffness matrix. Solve the resulting system of equations for \\( u(x) \\) assuming a given source function \\( f(x) \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix},\n    \\]\n    use SVD to compute its rank, and then use this information to describe the nullity of \\( A \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Discuss the concept of mesh refinement in the finite element method. How does refining the mesh improve the accuracy of the solution? Explain the trade-off between computational cost and accuracy.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Show that the columns of the matrix \\( U \\) in the SVD of \\( A \\) are orthonormal. That is, prove that \\( U^T U = I \\) where \\( I \\) is the identity matrix.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Complete the square for \\( x^H A x \\). Now \\( x^H = [x_1 \\, x_2] \\) can be complex\n        \\[\n        a |x_1|^2 + 2\\text{Re}(b)x_1 x_2 + c |x_2|^2 = a \\left| x_1 + \\frac{b}{a} x_2 \\right|^2 + |x_2|^2.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "For a 1D finite element model, derive the system of equations for a structure subjected to both internal and external forces. Explain how the stiffness matrix is assembled and solve for the displacements at the nodes.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "If a 2 by 2 symmetric matrix passes the tests \\( a > 0 \\), \\( ac > b^2 \\), solve the quadratic equation \\( \\det(A - \\lambda I) = 0 \\) and show that both eigenvalues are positive.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Find the minimum values of}\n    \\[\n    R(x) = \\frac{x_1^2 - x_1 x_2 + x_2^2}{x_1^2 + x_2^2}\n    \\]\n    and\n    \\[\n    R(x) = \\frac{x_1^2 - x_1 x_2 + x_2^2}{2x_1^2 + x_2^2}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "The quadratic \\( f(x_1, x_2) = 3(x_1 + 2x_2)^2 + 4x_2^2 \\) is positive. Find its matrix \\( A \\), factor it into \\( LDL^T \\), and connect the entries in \\( D \\) and \\( L \\) to 3, 2, 4 in \\( f \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "State and explain Sylvester\u2019s criterion for testing positive definiteness. Apply this criterion to the matrix \n    \\[\n    A = \\begin{bmatrix} 4 & 2 \\\\ 2 & 3 \\end{bmatrix}\n    \\]\n    and determine if it is positive definite.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Factor \\( A = LDL^T \\) when \\( b \\) is in the range for positive definiteness.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Write down the five conditions for a 3 by 3 matrix to be negative definite (\\( -A \\) is positive definite) with special attention to condition III: How is \\( \\det(-A) \\) related to \\( \\det(A) \\)?}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Do \\( A \\) and \\( C^T A C \\) always satisfy the law of inertia when \\( C \\) is not square?}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "State and explain Ky Fan\u2019s inequalities in the context of matrix theory. Discuss their significance in optimization, particularly in the context of matrix eigenvalues. How can these inequalities be used to establish bounds in convex optimization problems involving eigenvalues of symmetric matrices? Apply Ky Fan's inequalities to the matrix \\( A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and determine its eigenvalue bounds.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\( F = -1 + 4(e^x - x) - 5x \\sin y + 6y^2 \\) at the point \\( x = y = 0 \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Show that the matrix \\( A \\) has the same singular values as the matrix \\( A^T \\). Prove this by computing the SVD of both \\( A \\) and \\( A^T \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Discuss the connection between the minimum principle and the concept of convexity in optimization. Prove that if the Hessian of the objective function is positive definite, the function is strictly convex, and hence the minimum principle guarantees a unique minimum.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the minimum principle in the context of functional optimization. Use this principle to determine the optimal value of the integral\n    \\[\n    \\int_0^1 (y''(x)^2 + y(x)^2) dx,\n    \\]\n    where \\( y(x) \\) is a function with boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 0 \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{Explain how \\( U \\Sigma V^T \\) expresses \\( A \\) as a sum of \\( r \\) rank-1 matrices in equation (3):}\n    \\[\n    A = \\sigma_1 u_1 v_1^T + \\cdots + \\sigma_r u_r v_r^T.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{If \\( A = Q \\Lambda Q^T \\) is symmetric positive definite, then \\( R = Q \\sqrt{\\Lambda} Q^T \\) is its symmetric positive definite square root. Why does \\( R \\) have positive eigenvalues? Compute \\( R \\) and verify \\( R^2 = A \\) for}\n    \\[\n    A = \\begin{bmatrix}\n    10 & 6 \\\\\n    6 & 10\n    \\end{bmatrix}, \\quad\n    A = \\begin{bmatrix}\n    10 & -6 \\\\\n    -6 & 10\n    \\end{bmatrix}\n    \\]",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Prove that if a matrix is positive definite, all its eigenvalues are positive. Provide an example of a positive definite matrix and demonstrate how the eigenvalues can be computed.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Show how the stiffness matrix for a 1D linear finite element problem can be derived using the Galerkin method. Assume the following linear trial function \\( \\hat{u}(x) \\) for the approximation of the displacement field:\n    \\[\n    \\hat{u}(x) = \\lambda_1 u_1 + \\lambda_2 u_2.\n    \\]\n    Calculate the stiffness matrix for this element.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the matrix\n    \\[\n    A = \\begin{bmatrix} 2 & 3 \\\\ 2 & 2 \\\\ 3 & 2 \\end{bmatrix},\n    \\]\n    compute the SVD of \\( A \\) and discuss the significance of the singular values in relation to the matrix's rank.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Define a positive definite matrix and explain its significance in optimization problems. Provide examples of how positive definite matrices are used in quadratic forms.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Given the function \\( f(x, y) = x^2 + 2y^2 - 4x + 4y \\), find the critical points and determine whether each point is a minimum, maximum, or saddle point using the second-derivative test.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Prove the L\u00f6wner-Heinz inequality for self-adjoint operators and discuss its significance in the context of convexity. How does this inequality relate to the optimization of convex functions over self-adjoint matrices or operators? Provide an example where this inequality is used to solve an optimization problem. Let \\( A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\) and \\( B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\), prove the L\u00f6wner-Heinz inequality and find its application in an optimization problem.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Derive the Singular Value Decomposition of a matrix. Show the steps involved in decomposing a matrix \\( A \\) into \\( A = U \\Sigma V^T \\), where \\( U \\), \\( \\Sigma \\), and \\( V \\) have specific properties.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Consider the function \\( f(x, y, z) = x^2 + y^2 + z^2 + 2xy - 4xz \\). Find and classify the critical points as minima, maxima, or saddle points using the second-derivative test.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Solve an optimization problem using matrix inequalities, such as maximizing a convex function subject to matrix constraints. Discuss the use of Ky Fan\u2019s inequalities and L\u00f6wner-Heinz inequality in obtaining optimal solutions for problems involving semidefinite matrices. Given \\( A = \\begin{pmatrix} 5 & 4 \\\\ 4 & 5 \\end{pmatrix} \\), solve the optimization problem \\( \\max \\text{Tr}(A X) \\) subject to \\( X \\succeq 0 \\) and \\( \\text{Tr}(X) = 1 \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{(Lyapunov test for stability of \\( M \\)) Suppose \\( A M + M^T A = -I \\) with positive definite \\( A \\). If \\( M x = \\lambda x \\), show that \\( \\text{Re}(\\lambda) < 0 \\). (Hint: Multiply the first equation by \\( x^T \\) and \\( x \\).)}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "\\textbf{With \\( A = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} \\), find a choice of \\( x \\) that gives a smaller \\( R(x) \\) than the bound \\( \\lambda_1 \\leq 2 \\) that comes from the diagonal entries. What is the minimum value of \\( R(x) \\)?}",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Use the minimum principle to solve the variational problem\n    \\[\n    J(y) = \\int_0^1 \\left( 2y'(x)^2 + y(x)^2 \\right) \\, dx.\n    \\]\n    Solve for the function \\( y(x) \\) that minimizes this functional subject to boundary conditions \\( y(0) = 0 \\) and \\( y(1) = 1 \\).",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "Use Sylvester\u2019s criterion to verify whether the matrix\n    \\[\n    A = \\begin{bmatrix} 3 & 4 \\\\ 4 & 6 \\end{bmatrix}\n    \\]\n    is positive definite.",
            "equations": []
        },
        {
            "chapter": "Positive Definite Matrices",
            "question_latex": "(b) Deduce that the \\( a_i \\)'s and \\( b_i \\)'s are zero (proving linear independence). From that, deduce \\( p + q \\leq n \\).",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "For which matrices $A$ is that region a square?",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The subspace spanned by $(1,1,1,1)$, $(1,2,3,4)$, and $(2,3,4,5)$.",
            "equations": [
                "(1,1,1,1)",
                "(1,2,3,4)",
                "(2,3,4,5)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\( Ax = b \\) has infinitely many solutions for every \\( b \\).",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{The ``cyclic'' transformation \\( T \\) is defined by}\n\\[\nT(v_1, v_2, v_3) = (v_2, v_3, v_1).\n\\]\nWhat is \\( T(T(T(v))) \\)? What is \\( T^{100}(v) \\)?\n\n% Question 28",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "$\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$ and $\\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$.",
            "equations": [
                "\\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}",
                "\\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{What is the axis and the rotation angle for the transformation that takes \\( (x_1, x_2, x_3) \\) into \\( (x_2, x_3, x_1) \\)?}\n\n% Question 21",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{1.2} By giving a basis, describe a two-dimensional subspace of $\\mathbb{R}^3$ that contains none of the coordinate vectors $(1,0,0)$, $(0,1,0)$, $(0,0,1)$.",
            "equations": [
                "\\mathbb{R}^3",
                "(1,0,0)",
                "(0,1,0)",
                "(0,0,1)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "a line.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What is the smallest subspace of $3 \\times 3$ matrices that contains all symmetric matrices and all lower triangular matrices? What is the largest subspace that is contained in both of those subspaces?",
            "equations": [
                "3 \\times 3"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "In elimination on $A$, what multiple of the third row is subtracted to knock out the fourth row?",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The two vectors $v_1$ and $v_2$ will be dependent if \\underline{\\hspace{5cm}}.",
            "equations": [
                "v_1",
                "v_2"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Prove that $\\text{rank}(AB) \\leq \\text{rank}(B)$.",
            "equations": [
                "\\text{rank}(AB) \\leq \\text{rank}(B)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Provide an example where the column spaces of $A$ and $AB$ are not equal.",
            "equations": [
                "A",
                "AB"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "$x + y = y + x$.",
            "equations": [
                "x + y = y + x"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\( w_1 = (1, 2, 0), w_2 = (2, 5, 0), w_3 = (0, 0, 2), w_4 = (0, 0, 0), \\) and any \\( b \\)?",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose $A$ is an $m \\times n$ matrix of rank $r$. Its reduced echelon form is $R$. Describe exactly the reduced row echelon form of $R^T$ (not $A^T$).",
            "equations": [
                "A",
                "m \\times n",
                "r",
                "R",
                "R^T",
                "A^T"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Explain why the following statements are false:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The vectors $(1, -3, 2)$, $(2, 1, -3)$, and $(-3, 2, 1)$.",
            "equations": [
                "(1, -3, 2)",
                "(2, 1, -3)",
                "(-3, 2, 1)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The columns of \\( A \\) are \\( n \\) vectors from \\( \\mathbb{R}^m \\). If they are linearly independent, what is the rank of \\( A \\)? If they span \\( \\mathbb{R}^m \\), what is the rank? If they are a basis for \\( \\mathbb{R}^m \\), what then?\n\n% Question 24",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{If \\( Ax = 0 \\) has a nonzero solution, show that \\( A^T y = f \\) fails to be solvable for some right-hand sides \\( f \\).}  \nConstruct an example of \\( A \\) and \\( f \\).\n\n% Question 12",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The vectors $b$ not in $C(A)$ form a subspace.",
            "equations": [
                "b",
                "C(A)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{With the last column removed from the preceding \\( A \\), and with the numbers \\( 1, 2, 2, 1 \\) on the diagonal of \\( C \\), write out the \\( 7 \\times 7 \\) system:}\n\\[\nC^{-1} y + Ax = 0\n\\]\n\\[\nA^T y = f.\n\\]\nEliminating \\( y_1, y_2, y_3, y_4 \\) leaves three equations:\n\\[\nA^T C A x = -f.\n\\]\nSolve the equations when \\( f = (1,1,6) \\).  \nWith those currents entering nodes \\( 1,2,3 \\) of the network, what are the potentials at the nodes and currents on the edges?\n    % Question 12",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{M is any 2 by 2 matrix and \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\). The linear transformation \\( T \\) is defined by \\( T(M) = AM \\). What rules of matrix multiplication show that \\( T \\) is linear?}\n\n% Question 32",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Suppose \\( T(M) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} M \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\).}  \nFind a matrix with \\( T(M) \\neq 0 \\). Describe all matrices with \\( T(M) = 0 \\) (the kernel of \\( T \\)) and all output matrices \\( T(M) \\) (the range of \\( T \\)).\n\n% Question 36",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Which of these transformations satisfy \\( T(v+w) = T(v) + T(w) \\), and which satisfy \\( T(cv) = cT(v) \\)?}\n\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Suppose \\( T(v) = v \\), except that \\( T(0, v_2) = (0,0) \\).}  \nShow that this transformation satisfies \\( T(cv) = cT(v) \\) but not \\( T(v+w) = T(v) + T(w) \\).\n\n% Question 25",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Compute the \\( 3 \\times 3 \\) matrix \\( A^T A \\), and show that it is symmetric but singular.}  \nWhat vectors are in its nullspace?  \nRemoving the last column of \\( A \\) (and last row of \\( A^T \\)) leaves the \\( 2 \\times 2 \\) matrix in the upper left corner; show that it is not singular.\n\n% Question 5",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find $x_p$ and all special solutions for:\n    \\begin{align*}\n        Ax &= 2b, & \\begin{bmatrix} A & A \\end{bmatrix} \\begin{bmatrix} x \\\\ X \\end{bmatrix} &= b.\n    \\end{align*}",
            "equations": [
                "x_p"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "All sequences $(x_1, x_2, ...)$ with $x_j = 0$ from some point onward.",
            "equations": [
                "(x_1, x_2, ...)",
                "x_j = 0"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find a matrix with that subspace as its nullspace.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The number of 1s in $R$.",
            "equations": [
                "R"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If $w_1$, $w_2$, $w_3$ are independent vectors, show that the sums $v_1 = w_2 + w_3$, $v_2 = w_1 + w_3$, and $v_3 = w_1 + w_2$ are independent. (Write $c_1 v_1 + c_2 v_2 + c_3 v_3 = 0$ in terms of the $w$'s. Find and solve equations for the $c$'s.)\n\n% Question 9",
            "equations": [
                "w_1",
                "w_2",
                "w_3",
                "v_1 = w_2 + w_3",
                "v_2 = w_1 + w_3",
                "v_3 = w_1 + w_2",
                "c_1 v_1 + c_2 v_2 + c_3 v_3 = 0",
                "w",
                "c"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Those vectors (are)(are not)(might be) linearly independent.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Put as many $1$s as possible in a $4 \\times 7$ echelon matrix $U$ and in a reduced form $R$ whose pivot columns are $2, 4, 5$.",
            "equations": [
                "1",
                "4 \\times 7",
                "U",
                "R",
                "2, 4, 5"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find all functions that satisfy \\( \\frac{dy}{dx} = 0 \\).",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What is the general solution to $Ax = 0$?",
            "equations": [
                "Ax = 0"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Invent a vector space that contains all linear transformations from $\\mathbb{R}^n$ to $\\mathbb{R}^n$. You have to decide on a rule for addition. What is its dimension?",
            "equations": [
                "\\mathbb{R}^n",
                "\\mathbb{R}^n"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Suppose \\( A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 6 \\end{pmatrix} \\).}  \nShow that the identity matrix \\( I \\) is not in the range of \\( T \\). Find a nonzero matrix \\( M \\) such that \\( T(M) = AM \\) is zero.\n% Question 33",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What is the rank of the $n \\times n$ matrix with every entry equal to 1? How about the \u201ccheckerboard matrix,\u201d with $a_{ij} = 0$ when $i + j$ is even, $a_{ij} = 1$ when $i + j$ is odd?",
            "equations": [
                "n \\times n",
                "a_{ij} = 0",
                "i + j",
                "a_{ij} = 1",
                "i + j"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The reduced form $R$ of a $3 \\times 3$ matrix with randomly chosen entries is almost sure to be\\dots What $R$ is virtually certain if the random $A$ is $4 \\times 3$?\n\n% Question 68",
            "equations": [
                "R",
                "3 \\times 3",
                "R",
                "A",
                "4 \\times 3"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Put the diagonal matrix \\( C \\) with entries \\( c_1, c_2, c_3 \\) in the middle and compute \\( A^T C A \\).}  \nShow again that the \\( 2 \\times 2 \\) matrix in the upper left corner is invertible.\n\n% Question 6",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The row space of $U$.",
            "equations": [
                "U"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Redraw Figure 2.5 for a \\( 3 \\times 2 \\) matrix of rank \\( r = 2 \\). Which subspace is \\( Z \\) (zero vector only)? The nullspace part of any vector \\( x \\) in \\( \\mathbb{R}^2 \\) is \\( x_n = \\) \\dots}\n    % Question 1",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "True or false, with counterexample if false:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If the rows of $A$ are linearly independent (where $A$ is $m \\times n$), then the rank is \\_, the column space is \\_, and the left nullspace is \\_.",
            "equations": [
                "A",
                "A",
                "m \\times n"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "An invertible matrix has no free variables.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Decide whether or not the following vectors are linearly independent, by solving \\( c_1 v_1 + c_2 v_2 + c_3 v_3 + c_4 v_4 = 0 \\):\n    \\[\n    v_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \n    v_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \n    v_3 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}, \n    v_4 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n    \\]\n    Decide also if they span \\( \\mathbb{R}^4 \\), by trying to solve \\( c_1 v_1 + \\dots + c_4 v_4 = (0, 0, 0, 1) \\).\n\n% Question 17",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose all $r$ pivot variables come last. Describe the four blocks in the $m \\times n$ reduced echelon form (the block $B$ should be $r \\times r$):\n    \\begin{equation*}\n        R = \\begin{bmatrix} A & B \\\\ C & D \\end{bmatrix}.\n    \\end{equation*}\n    What is the nullspace matrix $N$ of special solutions? What is its shape?",
            "equations": [
                "r",
                "m \\times n",
                "B",
                "r \\times r",
                "N"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If the sum of the ``vectors'' $f(x)$ and $g(x)$ in $F$ is defined to be $f(g(x))$, then the ``zero vector'' is $g(x) = x$. Keep the usual scalar multiplication $c f(x)$, and find two rules that are broken.",
            "equations": [
                "f(x)",
                "g(x)",
                "F",
                "f(g(x))",
                "g(x) = x",
                "c f(x)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "An $m \\times n$ matrix has no more than $n$ pivot variables.",
            "equations": [
                "m \\times n",
                "n"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The column space (in \\( \\mathbb{R}^2 \\)) and null space (in \\( \\mathbb{R}^5 \\)) of  \n        \\[\n        U =\n        \\begin{bmatrix}\n        1 & 0 & 1 & 0 & 1 \\\\\n        0 & 1 & 0 & 1 & 0\n        \\end{bmatrix}.\n        \\]",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "infinitely many solutions for every $b$.",
            "equations": [
                "b"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose $A$ and $B$ are $n \\times n$ matrices and $AB = I$. Prove that $A$ is invertible.",
            "equations": [
                "A",
                "B",
                "n \\times n",
                "AB = I",
                "A"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "0 or 1, depending on $b$.",
            "equations": [
                "b"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose $P$ is a plane through $(0,0,0)$ and $L$ is a line through $(0,0,0)$. The smallest vector space containing both $P$ and $L$ is either \\underline{ } or \\underline{ }.",
            "equations": [
                "P",
                "(0,0,0)",
                "L",
                "(0,0,0)",
                "P",
                "L"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The $4 \\times 4$ Hadamard matrix is entirely $+1$ and $-1$:\n    \\[\n    H = \\begin{bmatrix}\n    1 & 1 & 1 & 1 \\\\\n    1 & -1 & 1 & -1 \\\\\n    1 & 1 & -1 & -1 \\\\\n    1 & -1 & -1 & 1\n    \\end{bmatrix}.\n    \\]\n    Find $H^{-1}$ and write $v = (7,5,3,1)$ as a combination of the columns of $H$.",
            "equations": [
                "4 \\times 4",
                "+1",
                "-1",
                "H^{-1}",
                "v = (7,5,3,1)",
                "H"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find all functions that satisfy \\( \\frac{dy}{dx} = 3 \\).",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The equation \\( Ax = 0 \\) has only the solution \\( x = 0 \\) because \\_\\_\\_.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Carry out the same steps as in the previous problem to find the complete solution of $Mx = b$:\n    \\[\n    M = \\begin{bmatrix} 0 & 0 \\\\ 1 & 2 \\\\ 0 & 0 \\\\ 3 & 6 \\end{bmatrix}, \\quad\n    b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}.\n    \\]",
            "equations": [
                "Mx = b"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If $a$, $d$, and $f$ in Problem 3 are all nonzero, show that the only solution to $U x = 0$ is $x = 0$. Then $U$ has independent columns.",
            "equations": [
                "a",
                "d",
                "f",
                "U x = 0",
                "x = 0",
                "U"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The number of columns minus the total number of rows.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Reduce $A$ and $B$ to echelon form, to find their ranks. Which variables are free?\n    \\[\n    A = \\begin{bmatrix}\n        1 & 2 & 0 & 1 \\\\\n        0 & 1 & 1 & 0 \\\\\n        1 & 2 & 0 & 1\n    \\end{bmatrix}, \\quad\n    B = \\begin{bmatrix}\n        1 & 2 & 3 \\\\\n        4 & 5 & 6 \\\\\n        7 & 8 & 9\n    \\end{bmatrix}\n    \\]\n    Find the special solutions to $Ax = 0$ and $Bx = 0$. Find all solutions.",
            "equations": [
                "A",
                "B",
                "Ax = 0",
                "Bx = 0"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Why does the nullspace of \\( A^T A \\) contain \\( (1,1,1,1) \\)? What is its rank?}\n\n% Question 20",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose \\( S \\) is a five-dimensional subspace of \\( \\mathbb{R}^6 \\). True or false?\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Describe the set of attainable right-hand sides $b$ (in the column space) for\n    \\[\n    \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 2 & 3 \\end{bmatrix}\n    \\begin{bmatrix} u \\\\ v \\end{bmatrix} =\n    \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix},\n    \\]\n    by finding the constraints on $b$ that turn the third equation into $0 = 0$ (after elimination). What is the rank, and a particular solution?",
            "equations": [
                "b",
                "b",
                "0 = 0"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What is the null space matrix $N$ (of special solutions) for $A$, $B$, $C$?\n    \\[\n    A = \\begin{bmatrix} I & I \\end{bmatrix}, \\quad B = \\begin{bmatrix} I & I \\\\ 0 & 0 \\end{bmatrix}, \\quad C = \\begin{bmatrix} I & I & I \\end{bmatrix}.\n    \\]",
            "equations": [
                "N",
                "A",
                "B",
                "C"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose $A$ and $B$ have the same reduced row echelon form $R$. Explain how $A$ can be transformed into $B$.",
            "equations": [
                "A",
                "B",
                "R",
                "A",
                "B"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "$\\begin{bmatrix} 1 & 4 \\\\ 2 & 9 \\\\ -1 & -4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}.$",
            "equations": [
                "\\begin{bmatrix} 1 & 4 \\\\ 2 & 9 \\\\ -1 & -4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}."
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If $Ax = Ay$, then $x = y$.",
            "equations": [
                "Ax = Ay",
                "x = y"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\( \\begin{bmatrix} A \\\\ A \\end{bmatrix} \\) and \\( \\begin{bmatrix} A & A \\\\ A & A \\end{bmatrix} \\).",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What subspace is spanned by the permutation matrices?",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{The adjacency matrix of a graph has \\( M_{ij} = 1 \\) if nodes \\( i \\) and \\( j \\) are connected by an edge (otherwise \\( M_{ij} = 0 \\)).}  \nFor the graph in Problem 6 with 6 nodes and 4 edges, write down \\( M \\) and also \\( M^2 \\).  \nWhy does \\( (M^2)_{ij} \\) count the number of 2-step paths from node \\( i \\) to node \\( j \\)?\n    % Question 1",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find a basis for each of these subspaces of \\( 3 \\times 3 \\) matrices:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The only solution to $Ax = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ is $x = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.",
            "equations": [
                "Ax = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}",
                "x = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Review: Suppose \\( A \\) is \\( 5 \\times 4 \\) with rank 4.}  \nShow that \\( Ax = b \\) has no solution when the \\( 5 \\times 5 \\) matrix \\( [A \\; b] \\) is invertible.  \nShow that \\( Ax = b \\) is solvable when \\( [A \\; b] \\) is singular.\n\n    % Question 1",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{The transformation \\( T \\) that transposes every matrix is definitely linear. Which of these extra properties are true?}\n\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Addition and scalar multiplication are required to satisfy these eight rules:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The column space of a \\( 2 \\times 2 \\) matrix has the same dimension as its row space.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Describe the three types of subspaces of $\\mathbb{R}^2$.",
            "equations": [
                "\\mathbb{R}^2"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The intersection of a plane through $(0,0,0)$ with a line through $(0,0,0)$ is probably a \\underline{ } but it could be a \\underline{ }.",
            "equations": [
                "(0,0,0)",
                "(0,0,0)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "If those vectors are the columns of \\( A \\), then \\( Ax = b \\) (has) (does not have) (might not have) a solution.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The vectors for which $x_1 + x_2 + x_3 = 0$ and $x_3 + x_4 = 0$.",
            "equations": [
                "x_1 + x_2 + x_3 = 0",
                "x_3 + x_4 = 0"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find the ranks of $AB$ and $AM$ for:\n    \\begin{align*}\n        A &= \\begin{bmatrix} 1 & 2 \\\\ 2 & 4 \\end{bmatrix},\n        &B &= \\begin{bmatrix} 2 & 1 & 4 \\\\ 3 & 1.5 & 6 \\end{bmatrix},\n        &M &= \\begin{bmatrix} 1 & b \\\\ c & bc \\end{bmatrix}.\n    \\end{align*}",
            "equations": [
                "AB",
                "AM"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "$(c_1 c_2)x = c_1 (c_2 x)$.",
            "equations": [
                "(c_1 c_2)x = c_1 (c_2 x)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The number of columns minus the total number of rows.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What is the dimension of the left nullspace of $A$?",
            "equations": [
                "A"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find a counterexample to the following statement: If \\( v_1, v_2, v_3, v_4 \\) is a basis for the vector space \\( \\mathbb{R}^4 \\), and if \\( W \\) is a subspace, then some subset of the \\( v \\)'s is a basis for \\( W \\).\n\n% Question 32",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The two column spaces.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Construct a matrix whose left nullspace contains $y = (1,5)$.",
            "equations": [
                "y = (1,5)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Is there a $3 \\times 3$ matrix with no zero entries for which $U = R = I$?",
            "equations": [
                "3 \\times 3",
                "U = R = I"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The three vectors $(0, 1, 1)$, $(1, 1, 0)$, and $(0, 0, 0)$.",
            "equations": [
                "(0, 1, 1)",
                "(1, 1, 0)",
                "(0, 0, 0)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "The matrix that transforms $(1,0)$ and $(0,1)$ to $(1,4)$ and $(1,5)$ is $M = \\cdots$. The combination $a(1,4) + b(1,5)$ that equals $(1,0)$ has $(a,b) = (\\cdots)$. How are those new coordinates of $(1,0)$ related to $M$ or $M^{-1}$?",
            "equations": [
                "(1,0)",
                "(0,1)",
                "(1,4)",
                "(1,5)",
                "M = \\cdots",
                "a(1,4) + b(1,5)",
                "(1,0)",
                "(a,b) = (\\cdots)",
                "(1,0)",
                "M",
                "M^{-1}"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Use elimination to find the triangular factors in $A = LU$, if\n    \\[\n    A = \\begin{bmatrix}\n    a & a & a & a \\\\\n    a & b & b & b \\\\\n    a & b & c & c \\\\\n    a & b & c & d\n    \\end{bmatrix}\n    \\]\n    Under what conditions on the numbers $a$, $b$, $c$, $d$ are the columns linearly independent?",
            "equations": [
                "A = LU",
                "a",
                "b",
                "c",
                "d"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Suppose a linear transformation \\( T \\) transforms \\( (1, 1) \\) to \\( (2, 2) \\) and \\( (2, 0) \\) to \\( (0, 0) \\). Find \\( T(v) \\) when:}\n\\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Let $P$ be the plane in $\\mathbb{R}^3$ with equation $x + 2y + z = 6$. What is the equation of the plane $P_0$ through the origin parallel to $P$? Are $P$ and $P_0$ subspaces of $\\mathbb{R}^3$?",
            "equations": [
                "P",
                "\\mathbb{R}^3",
                "x + 2y + z = 6",
                "P_0",
                "P",
                "P",
                "P_0",
                "\\mathbb{R}^3"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "True or false: If we know $T(v)$ for $n$ different nonzero vectors in $\\mathbb{R}^2$, then we know $T(v)$ for every vector in $\\mathbb{R}^n$.",
            "equations": [
                "T(v)",
                "n",
                "\\mathbb{R}^2",
                "T(v)",
                "\\mathbb{R}^n"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "What are the three equations for $A$, $B$, $C$ if the parabola $Y = A + Bx + Cx^2$ equals $4$ at $x = a$, $5$ at $x = b$, and $6$ at $x = c$? Find the determinant of the $3 \\times 3$ matrix. For which numbers $a$, $b$, $c$ will it be impossible to find this parabola $Y$?",
            "equations": [
                "A",
                "B",
                "C",
                "Y = A + Bx + Cx^2",
                "4",
                "x = a",
                "5",
                "x = b",
                "6",
                "x = c",
                "3 \\times 3",
                "a",
                "b",
                "c",
                "Y"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Suppose \\( A \\) is a linear transformation from the x-y plane to itself. Why does \\( A^{-1} (x + y) = A^{-1} x + A^{-1} y \\)?}  \nIf \\( A \\) is represented by the matrix \\( M \\), explain why \\( A^{-1} \\) is represented by \\( M^{-1} \\).\n\n% Question 13",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "How can you construct a matrix that transforms the coordinate vectors $e_1, e_2, e_3$ into three given vectors $v_1, v_2, v_3$? When will that matrix be invertible?",
            "equations": [
                "e_1, e_2, e_3",
                "v_1, v_2, v_3"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Every $m \\times n$ matrix of rank $r$ reduces to $(m \\times r)$ times $(r \\times n)$:\n    \\[\n    A = (\\text{pivot columns of } A)(\\text{first } r \\text{ rows of } R) = (\\text{COL})(\\text{ROW}).\n    \\]",
            "equations": [
                "m \\times n",
                "r",
                "(m \\times r)",
                "(r \\times n)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\textbf{Compute \\( A^T A \\) and \\( A^T C A \\), where the \\( 6 \\times 6 \\) diagonal matrix \\( C \\) has entries \\( c_1, \\dots, c_6 \\).}  \nHow can you tell from the graph where the \\( c \\)'s will appear on the main diagonal of \\( A^T C A \\)?\n\n% Question 10",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Explain why the pivot rows and columns always give an invertible submatrix.",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Find the complete solutions of:\n    \\[\n    x + 3y + 3z = 1, \\quad 2x + 6y + 9z = 5, \\quad -x - 3y + 3z = 5.\n    \\]\n    \\[\n    \\begin{bmatrix} 1 & 3 & 1 & 2 \\\\ 2 & 6 & 4 & 8 \\\\ 0 & 0 & 2 & 4 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\\\ t \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 3 \\\\ 1 \\end{bmatrix}.\n    \\]",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "To decide whether \\( b \\) is in the subspace spanned by \\( w_1, \\dots, w_n \\), let the vectors \\( w \\) be the columns of \\( A \\) and try to solve \\( A x = b \\). What is the result for:\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "True or false (provide counterexamples if false):\n    \\begin{enumerate}",
            "equations": []
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "Suppose $T$ is the linear transformation on $\\mathbb{R}^3$ that takes each point $(u, v, w)$ to $(u+v+w, u+v, u)$. Describe what $T^{-1}$ does to the point $(x, y, z)$.",
            "equations": [
                "T",
                "\\mathbb{R}^3",
                "(u, v, w)",
                "(u+v+w, u+v, u)",
                "T^{-1}",
                "(x, y, z)"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "$A = \\begin{bmatrix} 1 & 2 & 2 & 4 & 6 \\\\ 1 & 2 & 3 & 6 & 9 \\\\ 0 & 0 & 1 & 2 & 3 \\end{bmatrix}$",
            "equations": [
                "A = \\begin{bmatrix} 1 & 2 & 2 & 4 & 6 \\\\ 1 & 2 & 3 & 6 & 9 \\\\ 0 & 0 & 1 & 2 & 3 \\end{bmatrix}"
            ]
        },
        {
            "chapter": "Vector Spaces",
            "question_latex": "\\begin{enumerate}",
            "equations": []
        }
    ]
}